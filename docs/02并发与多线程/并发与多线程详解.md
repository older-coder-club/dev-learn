# 并发与多线程面试指南（重排与扩展版）

评分说明：5=必须掌握，4=很重要，3=熟练更佳，2=了解即可，1=加分项  
结构说明：按“基础内核 → 同步原语 → 高级结构与模式 → 性能与诊断 → 新特性与扩展”层次重新排序。每个知识点依旧包含“是什么 / 为什么 / 怎么用 / 关键细节 / 面试提示”。

---

## 1. 线程 / 进程 / 虚拟线程 基础对比 [4]
- 是什么：进程具独立地址空间；操作系统线程为调度实体；虚拟线程（Loom）为 JVM 轻量调度单元，可挂起阻塞释放平台线程。
- 为什么：理解资源隔离与扩展限制，选择合适并发模型。
- 怎么用：CPU 密集用少量平台线程；高并发阻塞 IO 考虑虚拟线程；跨故障/安全边界用进程隔离。
- 关键细节：虚拟线程仍共享堆与锁；过度持有重量级锁会阻塞载体线程；ThreadLocal 大对象在虚拟线程中仍需谨慎。
- 面试提示：能说明虚拟线程优势来源于“阻塞映射为挂起”而非魔法速度提升。

## 2. 线程生命周期与状态 [3]
- 是什么：NEW → RUNNABLE → BLOCKED → WAITING → TIMED_WAITING → TERMINATED。
- 为什么：便于诊断卡顿与资源泄漏。
- 怎么用：使用 jstack 识别 BLOCKED vs WAITING；合理处理中断退出循环。
- 关键细节：中断为协作信号；守护线程不阻止 JVM 退出；ThreadLocal 需清理防泄漏。
- 面试提示：提供规范中断处理：捕获→恢复标志→清理→退出。

## 3. Java 内存模型 (JMM) 与 happens-before [5]
- 是什么：定义线程与主内存交互及重排序边界的规则集合。
- 为什么：保障在同步成立时的可见性与有序性，避免竞态读取未发布状态。
- 怎么用：利用锁释放→获取、volatile 写→读、线程启动/终止、final 构造完成等序关系设计正确发布。
- 关键细节：指令可重排但不改变单线程语义；双重检查需 volatile；构造期间泄露 this 破坏安全发布。
- 面试提示：能列表全部 happens-before 规则并解释 ++ 与 volatile 的关系。

## 4. 内存屏障与指令重排序示例 [3]
- 是什么：屏障限制特定方向的重排（LoadLoad/StoreStore/LoadStore/StoreLoad）。
- 为什么：建立跨线程可见性顺序，避免半初始化对象被读取。
- 怎么用：使用 volatile / 原子类 / 锁自动插入屏障；避免手写不安全发布。
- 关键细节：StoreLoad 最强（锁释放→获取隐含）；volatile 写前插入 StoreStore+StoreLoad，读后插入 LoadLoad+LoadStore。
- 面试提示：举“先发布引用后填充字段”导致读取默认值的反例。

## 5. volatile 正确使用与边界 [5]
- 是什么：提供可见性与禁止相关重排的轻量同步，不保证复合操作原子性。
- 为什么：减少锁开销传播简单状态（标记/配置）。
- 怎么用：停止标记、单例 DCL、配置快照引用、统计开关。
- 关键细节：仅适合单变量读写；不解决 ++、条件竞争；与原子类或锁配合处理复合逻辑。
- 面试提示：列“适用 vs 不适用”清单增强说服力。

## 6. synchronized 与锁状态升级 [5]
- 是什么：内置监视器锁，状态：无锁→偏向→轻量→重量级。
- 为什么：低竞争场景极低成本，语义清晰。
- 怎么用：保护共享写；缩小临界区；避免在需要超时/中断场景使用。
- 关键细节：轻量级锁依赖对象头 CAS；偏向撤销成本；重量级锁导致阻塞挂起。
- 面试提示：说明现代 JVM 优化后“无竞争 synchronized 并不慢”。

## 7. AQS 框架原理 [5]
- 是什么：抽象同步器，使用 state + CLH 变体队列 + CAS + park/unpark。
- 为什么：统一构建 ReentrantLock、Semaphore、Latch、RWLock、StampedLock 等。
- 怎么用：重写 tryAcquire(+Shared)/tryRelease 实现自定义同步器。
- 关键细节：独占 vs 共享模式；节点状态 SIGNAL/CANCELLED 等；自旋 + 阻塞混合策略。
- 面试提示：能画 acquire 流程简图与说明公平锁实现。

## 8. ReentrantLock / ReadWriteLock / StampedLock 对比 [5]
- 是什么：可重入锁、高并发读写分离锁、带乐观读戳锁。
- 为什么：提供中断、超时、公平、读扩展、乐观读取性能优化。
- 怎么用：tryLock(超时) 避免死锁；读多写少使用 RWLock；热点快速读用 StampedLock 乐观读 validate。
- 关键细节：StampedLock 不可重入；乐观读失败回退悲观；公平性降低吞吐。
- 面试提示：能给选择矩阵：控制能力需求 + 读写比例。

## 9. 原子类与 CAS / LongAdder [5]
- 是什么：封装无锁原子更新 (Atomic* / LongAdder / Accumulator)。
- 为什么：减少阻塞、提升轻竞争性能。
- 怎么用：AtomicReference 状态机；AtomicStampedReference 防 ABA；LongAdder 高并发计数。
- 关键细节：CAS 失败重试开销；LongAdder sum 延迟；ABA 用 stamp。
- 面试提示：清楚阐述“volatile vs Atomic”差异。

## 10. ConcurrentHashMap 深入与并行操作 [5]
- 是什么：高并发哈希表，桶链表/红黑树 + 协作扩容 + 弱一致迭代。
- 为什么：提升读写并发吞吐，避免全局锁。
- 怎么用：compute / computeIfAbsent / merge 原子更新；forEach/search/reduce 并行阈值控制。
- 关键细节：treeify 条件（>=8 且容量>=64）；协作迁移；size 近似；键值非 null。
- 面试提示：说明弱一致迭代的合理性与常见原子操作模式。

## 11. JUC 并发容器与同步工具总览 [4]
- 是什么：ConcurrentLinkedQueue、BlockingQueue 系列、CopyOnWriteArrayList、DelayQueue、Semaphore、CountDownLatch、CyclicBarrier、Phaser、Exchanger。
- 为什么：降低手写同步风险，针对模式优化。
- 怎么用：读多写少用 COW；限并发许可用 Semaphore；阶段同步用 Barrier/Phaser；交换对称数据用 Exchanger。
- 关键细节：DelayQueue 基于时间优先排序；Latch 一次性；Phaser 可动态注册。
- 面试提示：快速区分 Latch vs Barrier vs Phaser 场景。

## 12. Semaphore / RateLimiter 差异 [3]
- 是什么：Semaphore 控制“同时占用数”；RateLimiter/令牌桶控制“到达速率”。
- 为什么：避免误用导致尖峰或资源饱和。
- 怎么用：并行度→Semaphore；请求平滑→令牌桶（Guava、Redis Lua）。
- 关键细节：Semaphore 不限制进入速率；令牌桶维持平均速率可突发。
- 面试提示：常见混淆题要明确两个维度不同。

## 13. CountDownLatch / CyclicBarrier / Phaser 对比 [4]
- 是什么：一次性倒计数 / 可重用阶段栅栏 / 多阶段动态参与。
- 为什么：满足不同协作语义。
- 怎么用：预热等待→Latch；分批阶段聚合→Barrier；复杂多阶段流水→Phaser。
- 关键细节：BrokenBarrierException；Phaser arrive/arriveAndAwaitAdvance。
- 面试提示：选择依据：是否重用 + 动态参与 + 阶段粒度。

## 14. CompletableFuture 编排与异常处理 [4]
- 是什么：异步任务链的组合抽象。
- 为什么：避免回调嵌套，表达依赖关系。
- 怎么用：supplyAsync/runAsync → thenApply/thenCompose/thenCombine → allOf/anyOf → exceptionally/handle。
- 关键细节：commonPool 默认；阻塞 join() 位置谨慎；orTimeout/completeOnTimeout。
- 面试提示：回答 thenCompose vs thenApply、exceptionally vs handle。

## 15. ForkJoinPool 与工作窃取 [4]
- 是什么：分治递归任务池 + 双端队列窃取。
- 为什么：提高 CPU 利用，减少全局锁。
- 怎么用：RecursiveTask/Action + 阈值；避免阻塞；ManagedBlocker。
- 关键细节：本地 LIFO 提高缓存；窃取 FIFO 减少冲突。
- 面试提示：说明 parallelStream 不适合阻塞 IO。

## 16. 虚拟线程 (Project Loom) 实战要点 [4]
- 是什么：大量阻塞任务的轻量调度单元。
- 为什么：降低编写异步样板，支持海量并发。
- 怎么用：newVirtualThreadPerTaskExecutor / Thread.ofVirtual().start；保留同步风格。
- 关键细节：受限于阻塞的外部原语；重锁仍影响载体线程；ThreadLocal 仍占用。
- 面试提示：强调“高并发阻塞 IO”最佳受益场景。

## 17. 并发设计模式与实践 [4]
- 是什么：生产者消费者、批处理合并、分段锁、双缓冲、Actor、工作窃取、Disruptor。
- 为什么：提升吞吐与隔离延迟。
- 怎么用：队列削峰；批量 flush；分段锁减少热点；双缓冲读写分离。
- 关键细节：批处理幂等；Actor 单线程顺序；RingBuffer 减伪共享。
- 面试提示：能根据性能瓶颈挑模式示例。

## 18. 安全发布与不可变模式 [4]
- 是什么：确保对象完全初始化后被其他线程观察。
- 为什么：防止半初始化数据错误。
- 怎么用：final 字段 + 不可变集合；Holder 单例；volatile 引用更新。
- 关键细节：构造中勿泄露 this；防御性复制。
- 面试提示：对比错误 DCL 单例示例。

## 19. 死锁检测与预防策略 [5]
- 是什么：循环等待造成永不推进的状态。
- 为什么：会永久占用关键资源。
- 怎么用：统一锁顺序、tryLock + 超时、减少嵌套、并发结构替代。
- 关键细节：四条件（互斥/占有且等待/不可剥夺/循环等待）；ThreadMXBean 检测；BrokenBarrier 处理。
- 面试提示：清晰列四条件及破坏手段。

## 20. 并发性能调优与诊断 [4]
- 是什么：从指标与工具分析瓶颈（锁、队列、GC、上下文切换）。
- 为什么：避免盲目扩线程或随意加锁。
- 怎么用：JFR/jstack/async-profiler/Arthas；监控 p95/p99；分析锁等待分布。
- 关键细节：无限队列隐藏背压；锁等待高 > 执行时间需拆分。
- 面试提示：描述数据驱动改进案例。

## 21. 诊断工具与核心指标 [4]
- 是什么：JFR、jstack、jmap、perf、async-profiler、ThreadMXBean。
- 为什么：缩短定位时间，量化影响。
- 怎么用：基线对比、自动采集、异常阈值告警。
- 关键细节：Full GC 与锁等待叠加放大延迟；线程爆炸增加调度开销。
- 面试提示：列出关键指标：活跃线程、队列长度、拒绝次数、锁等待、STW 时间。

## 22. 常见并发 Bug 与规避 [4]
- 是什么：竞态、死锁、活锁、饥饿、伪共享、错误发布、写偏。
- 为什么：破坏正确性或性能。
- 怎么用：原子操作替代 check-then-act；锁顺序统一；版本戳解决 ABA；使用 validate 乐观读。
- 关键细节：活锁是持续重试退让；饥饿多见于不公平锁+高竞争。
- 面试提示：准备至少两个真实故障案例。

## 23. 伪共享与缓存行优化 [3]
- 是什么：同一缓存行多线程写入导致频繁失效。
- 为什么：增加总线流量降低吞吐。
- 怎么用：@Contended、分片数组、填充结构。
- 关键细节：需 JVM 参数；过度填充浪费内存。
- 面试提示：计数器分桶示例。

## 24. 并发与内存占用权衡 [3]
- 是什么：为减少竞争增加结构（分段/副本）。
- 为什么：空间换时间。
- 怎么用：LongAdder 分槽、分片 Map、CopyOnWrite 小集合。
- 关键细节：监控堆与对象数；GC 压力评估。
- 面试提示：说明优化后内存提升是设计取舍。

## 25. JVM 锁优化 (偏向/轻量/消除/粗化) [3]
- 是什么：运行时基于逃逸与竞争分析调整锁机制。
- 为什么：降低无竞争场景开销。
- 怎么用：避免跨线程共享临时对象；减少频繁小同步块震荡。
- 关键细节：偏向批量撤销；锁消除依赖逃逸分析。
- 面试提示：解释现代 synchronized 性能改善原因。

## 26. VarHandle / Unsafe 内存语义 [3]
- 是什么：VarHandle 提供分级访问语义；Unsafe 低层操作（受限）。
- 为什么：构建定制高性能结构减少屏障。
- 怎么用：getAcquire/setRelease 形成单向有序链；避免直接使用 Unsafe。
- 关键细节：opaque 最弱；组合语义精细控制。
- 面试提示：回答“为何引入 VarHandle”替代反射/Unsafe。

## 27. Disruptor / RingBuffer 模式 [3]
- 是什么：无锁高吞吐事件队列框架。
- 为什么：低延迟流水线处理。
- 怎么用：预分配环→序号发布→多消费者依赖管理。
- 关键细节：缓存行填充；序号屏障协作。
- 面试提示：对比阻塞队列优势与复杂度成本。

## 28. 双重检查锁单例 (DCL) 正确实现 [4]
- 是什么：延迟实例化模式。
- 为什么：节省启动时间与资源。
- 怎么用：volatile + 双层 if + synchronized。
- 关键细节：构造步骤重排序风险；替代：Holder、enum。
- 面试提示：用字节码顺序解释风险。

## 29. 并发测试：jcstress / JMH [3]
- 是什么：jcstress 验证内存语义；JMH 微基准测性能。
- 为什么：防止逻辑“看似正确”。
- 怎么用：jcstress 结果分类；JMH 预热+fork 防干扰。
- 关键细节：避免死代码消除；结果显式校验。
- 面试提示：强调生产与微基准差异。

## 30. Structured Concurrency 概念 (Loom 展望) [2]
- 是什么：以结构化作用域管理子任务生命周期。
- 为什么：简化泄漏与取消处理。
- 怎么用：ScopedValue 传递上下文；StructuredTaskScope 统一 join/cancel。
- 关键细节：仍在演进；与手动管理线程池对比。
- 面试提示：说明其解决“孤儿任务”问题。

## 31. Semaphore 与限流的补充对比 [3]
- 是什么：并行度 vs 速率控制。
- 为什么：不同资源保护维度。
- 怎么用：热点接口同时请求上限→Semaphore；接口 QPS 平滑→令牌桶。
- 关键细节：二者可组合：先速率再并发。
- 面试提示：给实际组合例子。

---

## 常见面试延伸追问与回答框架（扩展版，≥20题）

1. volatile 能替代锁做计数吗？不能，复合操作非原子。  
2. 双重检查锁为何需 volatile？防止重排序将引用提前暴露。  
3. ConcurrentHashMap 为什么迭代弱一致？降低全局加锁成本提升并发。  
4. LongAdder 什么时候不适合？需要实时精确读取或参与后续逻辑判断。  
5. synchronized 与 ReentrantLock 选择标准？需中断/超时/公平/条件队列则用 ReentrantLock，否则简单互斥用 synchronized。  
6. ReadWriteLock 写偏问题是什么？大量读锁占用导致写锁长期等待。  
7. StampedLock 乐观读如何验证？通过 stamp validate，失败回退悲观读锁。  
8. ForkJoinPool 阈值设置依据？拆分成本与任务处理时间比，避免过度细粒度。  
9. parallelStream 为什么不适合阻塞 IO？阻塞占用少量工作线程导致饥饿。  
10. CompletableFuture thenCompose 与 thenApply 区别？前者展开内部 future，后者仅映射结果值。  
11. 线程池核心参数估算方法？CPU 密集 core≈CPU；IO 密集 core≈CPU×(1+等待/计算比)。  
12. 为什么不推荐 Executors.newCachedThreadPool 滥用？无限增长线程可能耗尽资源。  
13. 死锁四条件及破坏方式？互斥/占有等待/不可剥夺/循环等待；破坏锁顺序或使用 tryLock 超时。  
14. CountDownLatch 与 join 区别？Latch 可等待任意任务集合，join 仅等待线程结束。  
15. Phaser 优势是什么？支持多阶段与动态注册参与者。  
16. 伪共享如何定位？性能分析发现高速写变量彼此干扰，缓存行命中率低。  
17. 为什么无竞争 synchronized 仍快？偏向/轻量级锁优化消除重量级阻塞。  
18. VarHandle 与原子类区别？提供更细粒度内存语义与对数组/字段统一访问抽象。  
19. Unsafe 不建议使用原因？非安全、可导致崩溃，兼容性差，受限权限。  
20. 虚拟线程与线程池差别？成本低，阻塞挂起不占平台线程，适合海量阻塞任务。  
21. RateLimiter 与 Semaphore 能否一起用？可以，先速率限制再并发限制。  
22. 为什么需要安全发布？避免其他线程看到部分初始化状态导致逻辑错误。  
23. computeIfAbsent 比双检更安全原因？单方法内原子语义避免竞态窗口。  
24. Lock 公平模式何时使用？防止饥饿，但吞吐降低，适合长持锁且需顺序公平场景。  
25. AQS 为什么使用自旋 + park？减少短期等待的阻塞开销，长等待再挂起。  
26. 为什么线程过多会降低吞吐？上下文切换和缓存失效开销增加。  
27. 如何检测生产死锁？ThreadMXBean.findDeadlockedThreads 定期扫描 + 告警。  
28. Actor 模型优势？消息串行保证不需锁，易于隔离状态。  
29. Disruptor 比 BlockingQueue 快的原因？环形缓冲预分配 + 序号屏障 + 减少伪共享。  
30. 什么时候选择 CopyOnWriteArrayList？读远多于写且列表较小，需稳定迭代。

---

## 重要度汇总
- JMM / happens-before [5]
- synchronized 与锁升级机制 [5]
- AQS 框架与实现原理 [5]
- ReentrantLock / ReadWriteLock / StampedLock [5]
- ConcurrentHashMap 深入与原子操作模式 [5]
- 线程池参数估算与调优 [5]
- volatile 使用边界 [5]
- 死锁预防与检测 [5]
- 原子类 / CAS / LongAdder [5]
- CompletableFuture 编排与异常处理 [4]
- ForkJoinPool / 工作窃取 [4]
- 虚拟线程 (Project Loom) [4]
- 并发设计模式与实践 [4]
- 安全发布 / 不可变对象 [4]
- 并发性能诊断与指标 [4]
- JUC 同步工具对比 (Semaphore/Latch/Barrier/Phaser) [4]
- CountDownLatch / Barrier / Phaser 语义区分 [4]
- 内存屏障与重排序 [3]
- 伪共享优化 [3]
- 并发与内存权衡 [3]
- JVM 锁优化机制 [3]
- VarHandle / Unsafe 语义 [3]
- Disruptor / RingBuffer [3]
- 并发测试 jcstress / JMH [3]
- RateLimiter vs Semaphore [3]
- Structured Concurrency 概念 [2]

(完)