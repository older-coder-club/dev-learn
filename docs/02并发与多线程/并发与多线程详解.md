# 并发与多线程面试指南（重排与扩展版）

评分说明：5=必须掌握，4=很重要，3=熟练更佳，2=了解即可，1=加分项  
结构说明：按“基础与线程模型 → 内存模型与可见性 → 同步原语与锁 → JUC 容器与工具 → 线程池与任务执行 → 高级模式与实践 → 性能与诊断 → 新特性与展望”分区整理，并在每个分区内大致按重要程度排序。每个知识点依旧包含“是什么 / 为什么 / 怎么用 / 关键细节 / 面试提示 / 案例 / 速记”。

---

## 一、基础与线程模型

### 1.1 线程/进程/虚拟线程对比 [4]
- 是什么：进程=资源/地址空间；OS 线程=调度实体；虚拟线程=Loom 轻量线程，阻塞转为挂起。
- 为什么：指导并发模型选择与资源预算。
- 怎么用：CPU 密集少线程；高并发阻塞 IO 用虚拟线程；跨边界用进程隔离。
- 关键细节：虚拟线程共享堆/锁；长持锁会阻塞载体线程；ThreadLocal 大对象需谨慎。
- 常见陷阱：把虚拟线程当“更快”误用；忽略锁导致载体线程饥饿。
- 面试提示：强调“阻塞=挂起”，不是魔法。
- 案例：将 10k 阻塞 HTTP 调用改虚拟线程，线程数降 95%，CPU 稳定。
- 速记：CPU→少线程；IO→虚拟线程；跨边界→进程。

### 1.2 线程生命周期与中断 [3]
- 是什么：NEW→RUNNABLE→BLOCKED/WAITING/TIMED_WAITING→TERMINATED；中断是协作信号。
- 为什么：定位卡顿与退出策略。
- 怎么用：正确处理中断（恢复标志或上抛）；守护线程不阻止退出。
- 关键细节：ThreadLocal 清理；jstack 识别 WAITING vs BLOCKED。
- 常见陷阱：吞 InterruptedException；忘记清理 ThreadLocal。
- 面试提示：给出中断处理模板。
- 案例：修复吞中断导致无法关闭的问题。
- 速记：中断=协作退出；捕获→恢复→清理→返回。

## 二、内存模型与可见性

### 2.1 JMM 与 happens-before [5]
- 是什么：可见性与有序性的规则集。
- 为什么：避免读取半初始化与竞态。
- 怎么用：利用锁/volatile/线程边界/final 构造完成建立 HB，具体实现机制在 2.2，volatile 的适用边界在 2.3 展开。
- 关键细节：指令可重排但不破坏单线程语义；DCL 需 volatile；this 逃逸破坏发布。
- 常见陷阱：认为 volatile 能保证 ++ 原子；构造期注册回调。
- 面试提示：背出 HB 规则与典型反例。
- 案例：DCL 单例加 volatile 解决未初始化读。
- 速记：HB 四钥匙：锁/volatile/线程启动终止/final。

### 2.2 内存屏障与重排序 [3]
- 是什么：LoadLoad/StoreStore/LoadStore/StoreLoad 屏障限制重排。
- 为什么：建立跨线程顺序。
- 怎么用：理解锁/volatile/原子类在底层插入屏障的方式，结合 2.1 的 HB 规则解释可见性语义。
- 关键细节：StoreLoad 最强；volatile 写前后含 Store/Load 屏障。
- 常见陷阱：自实现无锁发布不插屏障。
- 面试提示：举“先发引用后填充”的问题。
- 案例：引入锁后消除读取默认值。
- 速记：别手写屏障；用语言原语。

### 2.3 volatile 使用边界 [5]
- 是什么：轻量可见性+禁止相关重排；不保证复合原子性。
- 为什么：状态/标志传播无需重锁。
- 怎么用：关闭标志、配置引用、DCL，底层语义依赖 2.1/2.2 中的 HB 与内存屏障，不再重复展开实现细节。
- 关键细节：多变量一致性需锁/原子类；写频高开销大。
- 常见陷阱：volatile ++；复合检查-更新。
- 面试提示：列举“可/不可”清单。
- 案例：用 volatile 配置引用热替换。
- 速记：单值传播用；复合逻辑不用。

### 2.4 并发 vs 内存权衡 [3]
- 是什么：分段/副本换吞吐。
- 为什么：降低竞争。
- 怎么用：LongAdder 分槽；分片 Map；COW 小集合。
- 关键细节：监控堆/对象数/GC。
- 常见陷阱：为小收益付出大内存。
- 面试提示：量化取舍。
- 速记：空间换并发有度。

## 三、同步原语与锁

### 3.1 synchronized 与锁状态升级 [5]
- 是什么：监视器锁；无锁→偏向→轻量→重量。
- 为什么：无竞争时成本低，语义直观。
- 怎么用：小临界区；不可中断/超时场景优先；JVM 具体如何做偏向/轻量/消除/粗化等优化见 3.5。
- 关键细节：与 ReentrantLock 相比语义简单；在无竞争场景下性能经现代 JVM 优化后通常足够好。
- 常见陷阱：需要中断/超时还用 synchronized。
- 面试提示：现代 JVM 下无竞争并不慢。
- 案例：拆分临界区，锁等待时间下降 80%。
- 速记：简单互斥=sync；中断/超时/条件→ReentrantLock。

### 3.2 AQS 框架 [5]
- 是什么：state + CLH 队列 + CAS + park/unpark 的抽象框架，是 ReentrantLock、Semaphore、CountDownLatch 等的实现基础。
- 为什么：统一抽象获取/释放逻辑，简化各种同步器实现，避免每种都从零写队列和阻塞逻辑。
- 怎么用：实现自定义同步器时重写 tryAcquire/tryRelease(独占/共享) 等模板方法；业务开发通常只需知道常见同步器都基于此框架。
- 关键细节：公平/非公平队列选择；可中断/不可中断/可超时获取；获取失败入队、成功出队的基本流程。
- 常见陷阱：自定义同步器未正确处理中断与超时；释放不对称导致线程永远阻塞。
- 面试提示：画 acquire 流程图，然后点名 ReentrantLock 等“都基于 AQS”，避免在 3.3 再画一遍。
- 案例：自定义限流器（共享模式）利用 AQS 的共享获取模式实现稳定限流。
- 速记：state+FIFO 队列；独占/共享两条线。

### 3.3 ReentrantLock/ReadWriteLock/StampedLock [5]
- 是什么：可重入锁/读写锁/带乐观读戳锁，底层都基于 3.2 中的 AQS 框架实现。
- 为什么：提供中断/超时/条件队列/高性能读等高级能力，补足 synchronized 的场景局限。
- 怎么用：tryLock(超时) 防死锁；读多用 ReadWriteLock；超热读用 StampedLock 乐观读 validate，避免在这里展开 AQS 流程细节。
- 关键细节：StampedLock 不可重入；写饥饿；validate 失败回退悲观读；条件队列通过 Condition 与 Lock 绑定。
- 常见陷阱：在 StampedLock 中使用条件队列；忽略写饥饿导致重要写请求长期等不到机会。
- 面试提示：重点放在“如何根据场景选择锁类型”，实现细节如队列结构指向 3.2，不必重复。
- 案例：乐观读失败率<2% 吞吐+20%。
- 速记：控制→ReentrantLock；读多→ReadWriteLock；热读→StampedLock。

### 3.4 原子类/CAS/LongAdder [5]
- 是什么：Atomic*、LongAdder、Accumulator 封装无锁更新。
- 为什么：减少阻塞、提升轻竞争性能。
- 怎么用：AtomicReference 状态机；*StampedReference 防 ABA；LongAdder 高并发计数。
- 关键细节：CAS 自旋重试；LongAdder sum 非实时。
- 常见陷阱：读要求强一致仍用 LongAdder。
- 面试提示：volatile vs Atomic 区别。
- 案例：AtomicLong→LongAdder p99 降 15%。
- 速记：低争用 Atomic；高争用 LongAdder；需要版本戳用 Stamped。

### 3.5 JVM 锁优化（偏向/轻量/消除/粗化）[3]
- 是什么：HotSpot 在 synchronized 上做的运行时优化，包括偏向锁、轻量级锁、锁消除与锁粗化。
- 为什么：在无/低竞争场景下显著降低加锁/解锁开销，让 synchronized 在常见场景性能可接受。
- 怎么用：从代码层面主要是“配合优化”——减少跨线程共享对象、避免过度碎片化的小同步块，让编译器更易做锁消除/粗化。
- 关键细节：偏向锁在检测到竞争后会批量撤销；锁消除依赖逃逸分析；锁粗化会自动将多次小范围 lock 合并为大范围。
- 常见陷阱：误解“偏向锁=一定更快”，忽略批量撤销成本；在高竞争场景执着追求偏向锁收益。
- 面试提示：回答 synchronized 性能问题时，将“现代 JVM 锁优化”作为补充说明，而不是堆细节。
- 速记：不跨线程→可消除；小块过多→可粗化。

### 3.6 VarHandle/Unsafe 语义 [3]
- 是什么：VarHandle=标准化访问语义（plain/opaque/acquire/release/volatile）；Unsafe=受限底层。
- 为什么：细粒度内存序替代部分 Unsafe。
- 怎么用：getAcquire/setRelease 构建单向依赖；必要时 volatile。
- 关键细节：opaque 最弱仅可见；invokeExact 严格签名。
- 常见陷阱：误用 volatile 过度。
- 面试提示：为何引入 VarHandle。
- 速记：按需选语义；尽量避 Unsafe。

### 3.7 ThreadLocal 与内存泄漏 [4]
- 是什么：线程本地变量，为每个线程维护独立副本。
- 为什么：避免共享状态竞争（如日期格式器、上下文），减少锁与对象创建。
- 怎么用：`ThreadLocal.withInitial` 初始化；在线程池任务中使用后必须 `remove()`；适合存放轻量级、与请求强相关的上下文。
- 关键细节：ThreadLocalMap 使用弱引用 Key、强引用 Value；线程池线程长生命周期导致 Value 残留成“伪泄漏”；InheritableThreadLocal 会把父线程值拷贝到子线程。
- 常见陷阱：在线程池中设置 ThreadLocal 却不清理；在 ThreadLocal 中放大对象/连接；误以为弱引用 Key 就“不会泄漏”。
- 面试提示：重点说明“为什么在线程池场景 ThreadLocal 更危险”，以及标准 try-finally 清理模板。
- 案例：登录上下文保存在 ThreadLocal，未清理导致下一个请求读到上一个用户信息，出现越权问题。
- 速记：短命线程还好说；线程池必 remove()。

### 3.8 wait/notify 与 Condition 对比 [4]
- 是什么：Object 的 `wait/notify/notifyAll` 与基于 Lock 的 `Condition` 条件队列，两套等待/唤醒机制。
- 为什么：老代码大量使用 wait/notify，新代码更推荐 Condition，语义更清晰、支持多条件队列与可中断/超时。
- 怎么用：`wait`/`notifyAll` 必须在对应对象的 synchronized 临界区内调用；始终搭配“条件谓词 + while 循环”使用；Condition 使用 `lock.newCondition()` + `await/signalAll` 实现更复杂的等待逻辑。
- 关键细节：存在虚假唤醒，必须 while 重试条件；`notify` 可能造成线程永远不被唤醒；Condition 必须使用与之关联的同一个 Lock；Condition 的 `await` 可中断/可超时。
- 常见陷阱：用 if 包裹 wait；在错误的锁对象上 wait；用 notify 代替 notifyAll 在多消费者场景导致“丢信号”。
- 面试提示：能写出正确的生产者-消费者 wait/notify 模板，并说明虚假唤醒与 notifyAll 的取舍；再顺带说出 Condition 的优势。
- 案例：多消费者队列使用 notify 唤醒，导致有元素但某些消费者永远不醒，改为 notifyAll 后问题消失。
- 速记：wait 外必套 while；新代码优先 Condition。

## 四、JUC 容器与同步工具

### 4.1 ConcurrentHashMap 深入 [5]
- 是什么：桶+链/树，协作扩容，弱一致迭代。
- 为什么：高并发吞吐。
- 怎么用：compute/merge/computeIfAbsent；forEach/search/reduce 并行阈值。
- 关键细节：树化阈值≥8 且 cap≥64；size 近似；键值不可为 null。
- 常见陷阱：get→put 复合竞态；依赖 size 精确控制。
- 面试提示：为何提供弱一致迭代。
- 案例：merge 取代三步更新 TPS +18%。
- 速记：三件套；size 近似。

### 4.2 JUC 容器与同步工具总览 [4]
- 是什么：ConcurrentLinkedQueue/BlockingQueue 系列/COW/DelayQueue/Semaphore/Latch/Barrier/Phaser/Exchanger。
- 为什么：减少手写同步风险。
- 怎么用：COW 读多写少；Semaphore 控并发；Barrier/Phaser 分阶段；Exchanger 对称交换。
- 关键细节：Latch 一次性；Phaser 动态注册；SynchronousQueue 零缓冲。
- 常见陷阱：无限队列掩盖背压。
- 面试提示：Latch vs Barrier vs Phaser。
- 案例：定长队列+拒绝策略避免 OOM。
- 速记：定长队列+背压；阶段工具匹配场景。

### 4.3 Semaphore vs RateLimiter [3]
- 是什么：并发数量 vs 速率控制。
- 为什么：不同维度保护资源。
- 怎么用：热点并发→Semaphore；平滑 QPS→令牌桶。
- 关键细节：可组合：先速率再并发。
- 常见陷阱：用 Semaphore 期望限速。
- 面试提示：清晰区分维度。
- 案例：组合使用降低峰值抖动。
- 速记：并发≠速率；可叠加。

### 4.4 Latch/Barrier/Phaser 对比 [4]
- 是什么：一次性倒计数/可重用栅栏/多阶段动态参与。
- 为什么：满足不同协作语义。
- 怎么用：预热等待→Latch；分批聚合→Barrier；复杂多阶段→Phaser。
- 关键细节：BrokenBarrierException；Phaser arrive/arriveAndAwaitAdvance。
- 常见陷阱：栅栏破损未处理。
- 面试提示：是否重用/是否多阶段。
- 案例：批处理流水线用 Phaser 稳定推进。
- 速记：一次性→Latch；阶段→Barrier/Phaser。

### 4.5 Disruptor/RingBuffer [3]
- 是什么：无锁高吞吐队列框架。
- 为什么：低延迟流水线。
- 怎么用：预分配环、序号发布、屏障依赖。
- 关键细节：缓存行填充；序号屏障。
- 常见陷阱：复杂路由/不稳定流下收益打折。
- 面试提示：对比 BlockingQueue。
- 速记：稳定流+预分配。

### 4.6 BlockingQueue 典型实现与选型 [4]
- 是什么：支持阻塞 put/take 的队列，包括 `ArrayBlockingQueue`、`LinkedBlockingQueue`、`SynchronousQueue`、`PriorityBlockingQueue` 等。
- 为什么：实现生产者-消费者、线程池任务队列、限流/背压的基础设施，减少手写 wait/notify 错误。
- 怎么用：
	- 固定容量缓冲：`ArrayBlockingQueue`（数组、有界、可公平）；
	- 通用大多数场景：限制容量的 `LinkedBlockingQueue`；
	- 直连移交：`SynchronousQueue`，常用于“每个任务一个线程”；
	- 按优先级出队：`PriorityBlockingQueue`。
- 关键细节：无界队列（如默认 LinkedBlockingQueue 容量 Integer.MAX_VALUE）会掩盖背压并放大内存风险；`put/take` 阻塞，`offer/poll` 可非阻塞或带超时；`SynchronousQueue` 实际是“零缓冲”直接移交。
- 常见陷阱：线程池使用无界 LinkedBlockingQueue，导致任务无限堆积最终 OOM；用 PriorityBlockingQueue 却实现了不自反/不传递的比较器造成奇怪行为。
- 面试提示：被问“怎么实现异步日志/消息缓冲”时，先画 BlockingQueue 模型，再说明要有界+拒绝/丢弃策略。
- 案例：日志系统改用有界 LinkedBlockingQueue + 超过阈值时丢弃 debug 日志，稳定了内存占用。
- 速记：队列必限长；SynchronousQueue=零缓冲直传。

### 4.7 CopyOnWrite 容器深入 [3]
- 是什么：写时复制容器，如 `CopyOnWriteArrayList/CopyOnWriteArraySet`，写操作复制数组，读操作无需加锁。
- 为什么：在读远多于写且集合较小的场景下，提供极简且高性能的并发读访问（如监听器列表、白名单配置）。
- 怎么用：写操作（add/remove）较少、可接受写时 O(n) 开销；读操作遍历时不怕并发修改，迭代期间看到的是“快照”。
- 关键细节：每次写都会创建新数组，写放大明显；迭代不会抛 ConcurrentModificationException，但也看不到后续写；不适合大集合或频繁写场景。
- 常见陷阱：在大列表或高写入场景使用 COW 导致内存和 GC 压力巨大；误以为“线程安全”就适合所有并发场景。
- 面试提示：主动给出“三条件”：读多、写少、小集合，并举典型使用场景（监听器、路由表快照）。
- 案例：事件监听器列表改为 CopyOnWriteArrayList，去掉锁后读路径延迟显著下降，且逻辑更简单。
- 速记：读多写少小集合 → CopyOnWrite。

### 4.8 ConcurrentLinkedQueue 与无界队列背压 [3]
- 是什么：基于 CAS 的无锁链表队列 `ConcurrentLinkedQueue`，提供高并发非阻塞入队/出队。
- 为什么：在高并发下降低锁竞争，适合作为异步任务/消息缓冲的核心结构之一。
- 怎么用：用于日志收集、异步处理等“尽量不阻塞生产者”的场景；通常需要外围配合限流或丢弃策略实现背压。
- 关键细节：队列无界，生产速度长期大于消费速度会占满内存；`size()` 复杂度高且仅近似；弱一致遍历。
- 常见陷阱：把 CLQ 当“万能缓冲池”，不监控长度，导致服务在高峰期慢性 OOM；用 size 做精确控制逻辑。
- 面试提示：在“高并发日志/埋点上报”设计题中，先给出 CLQ + 批量消费，再强调需要监控与限流。
- 案例：埋点系统使用 CLQ 缓存事件，增加队列长度监控与限速后在高峰期不再 OOM。
- 速记：高并发无锁队列好，用前先想背压。

## 五、线程池与任务执行

### 5.1 CompletableFuture 编排与异常 [4]
- 是什么：声明式异步组合。
- 为什么：避免回调地狱。
- 怎么用：thenCompose/thenCombine/allOf/exceptionally/orTimeout。
- 关键细节：commonPool 不适合阻塞；join 阻塞位置谨慎；handle 会吞异常。
- 常见陷阱：thenApply 造成嵌套 Future。
- 面试提示：thenCompose vs thenApply。
- 案例：自建池+超时 p99 稳定。
- 速记：阻塞→自建池；展开→thenCompose；异常尾部收敛。

### 5.2 ForkJoinPool 与工作窃取 [4]
- 是什么：基于工作窃取算法的线程池，任务以分治递归方式拆分到每个工作线程的双端队列中。
- 为什么：通过工作线程之间相互“窃取”任务，提升 CPU 利用率，适合 CPU 密集型分治计算。
- 怎么用：设置合适的任务拆分阈值；仅用于 CPU 密集或很短暂的阻塞，并在真正阻塞时使用 ManagedBlocker；并行流 parallelStream 底层也复用 ForkJoinPool 的 commonPool，但具体并行流使用在 5.7 展开。
- 关键细节：本地队列 LIFO、被窃取队列 FIFO；任务拆分过细会放大调度开销。
- 常见陷阱：把大量阻塞 IO 任务塞进 ForkJoinPool；阈值过小导致任务碎片化。
- 面试提示：重点说明“阈值为何重要”以及“只适合 CPU 密集/短阻塞”。
- 案例：阈值调优后吞吐 +30%。
- 速记：合适阈值；CPU 密集优先。

### 5.3 虚拟线程 (Loom) 实战 [4]
- 是什么：轻量线程，阻塞自动挂起。
- 为什么：极简模型支持海量并发。
- 怎么用：newVirtualThreadPerTaskExecutor/Thread.ofVirtual()。
- 关键细节：重锁阻塞载体；ThreadLocal 内存放大；限流/背压仍需。
- 常见陷阱：把 CPU 密集改虚拟线程期望变快。
- 面试提示：最适阻塞 IO。
- 案例：爬虫并发数 10x，资源稳定。
- 速记：阻塞→挂起；谨慎锁与 ThreadLocal。

### 5.4 线程池参数估算与实践 [5]
- 是什么：核心/最大/队列/拒绝策略/线程工厂。
- 为什么：平衡吞吐与资源。
- 怎么用：CPU 密集 core≈CPU；IO 密集≈CPU×(1+阻塞/计算)；队列定长+拒绝策略。
- 关键细节：newCachedThreadPool 无界；监控队列/拒绝/活跃线程。
- 常见陷阱：盲目加线程；无背压。
- 面试提示：给估算公式与监控项。
- 速记：定长队列+度量调参。

### 5.5 ExecutorService 生命周期管理 [4]
- 是什么：`ExecutorService` 的创建、使用与关闭过程（`shutdown/shutdownNow/awaitTermination`）。
- 为什么：避免线程池泄漏、应用无法优雅关闭、任务变成“孤儿线程”。
- 怎么用：组件启动时创建线程池；停止时调用 `shutdown` 并 `awaitTermination` 一段时间，若超时则 `shutdownNow`；结合 JVM 钩子/容器生命周期统一管理。
- 关键细节：`shutdown` 只是不再接收新任务，已提交任务会继续执行；`shutdownNow` 会尝试中断正在执行的任务并返回未开始的任务列表；`isShutdown/isTerminated` 区分状态。
- 常见陷阱：线程池定义为 static 工具从不关闭；任务内部吞掉 InterruptedException 导致 `shutdownNow` 也无法真正终止线程。
- 面试提示：能熟练写出“优雅关闭线程池”的标准代码模板，并说明中断处理要点。
- 案例：应用重启缓慢，排查发现业务线程池未关闭，容器等待其自然结束；添加统一关闭逻辑后停机时间显著缩短。
- 速记：创建必配关闭；优雅关优先，暴力关兜底。

### 5.6 ScheduledThreadPoolExecutor 与定时任务并发 [3]
- 是什么：支持延迟与周期任务的线程池实现，替代老旧的 `Timer`。
- 为什么：Timer 单线程且异常会终止整个调度，不能充分利用多核；ScheduledThreadPoolExecutor 支持多线程与更丰富的调度策略。
- 怎么用：使用 `schedule`、`scheduleAtFixedRate`、`scheduleWithFixedDelay` 提交任务；自定义线程工厂设置线程名与未捕获异常处理器。
- 关键细节：`scheduleAtFixedRate` 以固定频率对齐时间轴，任务执行时间长可能产生堆积；`scheduleWithFixedDelay` 以上一次任务结束时间为基准；任务异常未捕获会导致该任务后续不再执行。
- 常见陷阱：使用单线程定时池跑多个长任务，导致任务排队延迟；定时任务内部异常未处理导致周期任务“悄悄停掉”。
- 面试提示：被问“如何实现心跳/定时刷新缓存”，给出 ScheduledThreadPoolExecutor + 异常兜底 + 监控。
- 案例：缓存刷新任务因一次 NPE 停止执行，改为捕获异常并记录日志后问题解决。
- 速记：定时任务 → ScheduledPool；异常自己兜。

### 5.7 parallelStream 实战与坑 [3]
- 是什么：基于 ForkJoinPool commonPool 的并行流，通过 `.parallel()` 自动拆分任务执行流水线操作。
- 为什么：在无需显式管理 ForkJoinPool 的情况下，快速并行化 CPU 密集型批处理逻辑，简化代码。
- 怎么用：对纯计算、无共享可变状态、对结果顺序不敏感或有专门终端操作的流水线使用 parallelStream；如需自定义线程池，使用 `ForkJoinPool` + `submit(() -> stream.parallel()...)`，工作窃取细节见 5.2。
- 关键细节：默认使用全局 commonPool，与应用其他 parallelStream/ForkJoin 使用者共享；不适合阻塞 IO 或持锁操作；线程数≈CPU 核数。
- 常见陷阱：在 Web 请求线程中调用 parallelStream，阻塞有限的工作线程；在 parallelStream 中操作共享可变集合导致竞态；把它当成“通用加速器”用于 IO 密集场景。
- 面试提示：回答时先明确“底层就是 ForkJoinPool commonPool”，再强调适用/不适用场景，而不再解释工作窃取细节。
- 案例：离线报表分析使用 parallelStream，将处理时间从 30 分钟降到 10 分钟；在线接口误用 parallelStream 导致线程池饱和。
- 速记：离线纯计算可用；在线阻塞场景慎用。

### 5.8 ThreadLocalRandom 与随机数并发 [2]
- 是什么：线程局部的高性能随机数生成器，避免多线程共享 Random 的竞争。
- 为什么：在高并发路径需要大量随机数时，减少锁/伪共享，提升吞吐。
- 怎么用：在多线程代码中用 `ThreadLocalRandom.current().nextInt()` 等方法代替共享 Random；JDK8+ 还可使用 SplittableRandom 做并行计算。
- 关键细节：ThreadLocalRandom 不支持手动设置种子；ThreadLocalRandom 只适合单进程统计意义的“足够随机”。
- 常见陷阱：在高频路径频繁 new Random 导致种子质量差且 GC 压力大；在全局共享一个 Random 导致锁竞争严重。
- 面试提示：随机数题目可顺带指出“Random 的并发问题与改进方案”。
- 案例：订单号生成用共享 Random，QPS 升高后 CPU 出现锁争用高，改为 ThreadLocalRandom 后恢复正常。
- 速记：多线程随机 → ThreadLocalRandom。

## 六、高级并发模式与实践

### 6.1 并发设计模式 [4]
- 是什么：生产者-消费者、批量合并、分段锁、双缓冲、Actor、Disruptor。
- 为什么：提升吞吐/隔离延迟。
- 怎么用：队列削峰；批量 flush；分段锁；Actor 单线程。
- 关键细节：幂等；背压水位；缓存行填充。
- 常见陷阱：无限积压；批量无边界。
- 面试提示：按瓶颈选模式。
- 案例：批量合并 QPS +40%。
- 速记：削峰/批量/隔离/单线程。

### 6.2 安全发布与不可变 [4]
- 是什么：完全初始化后对外可见；不可变对象天然线程安全。
- 为什么：避免半初始化与竞态。
- 怎么用：final 字段；构造不泄露；volatile 引用更新；不可变集合。
- 关键细节：防御性复制；记录类/值对象。
- 常见陷阱：返回内部可变集合。
- 面试提示：Holder/enum 单例。
- 案例：不可变配置避免加锁。
- 速记：final+不泄露；返回副本。

### 6.3 死锁检测与预防 [5]
- 是什么：多个线程间形成循环等待，导致相关线程永久阻塞的状态。
- 为什么：会长时间占用关键资源，造成请求堆积甚至系统雪崩。
- 怎么用：统一加锁顺序；使用 tryLock+超时/回退；减少嵌套锁与跨组件锁；检测手段（如 ThreadMXBean）在 7.2、常见问答 13/27 中补充，不在此展开工具细节。
- 关键细节：死锁四必要条件（互斥、占有且等待、不可剥夺、循环等待）；设计时有意识地破坏其中之一。
- 常见陷阱：多个锁无全局顺序；异常路径未释放锁；为“图省事”在回调中再拿外层锁。
- 面试提示：组织答案为“先讲四条件，再讲如何破坏，再给一条统一加锁顺序的工程实践”，检测工具可以一句话带过即可。
- 案例：为所有资源定义统一加锁顺序并做 code review 后，历史死锁告警消失。
- 速记：统一顺序+超时回退，工具只是辅助。

### 6.4 并发性能调优与诊断 [4]
- 是什么：指标驱动优化。
- 为什么：避免拍脑袋调参数。
- 怎么用：JFR/jstack/async-profiler；监控 p95/p99/锁等待/队列长度。
- 关键细节：无限队列掩盖背压；锁等待>执行时间要拆。
- 常见陷阱：盲目加线程。
- 面试提示：四步法：度量→采样→优化→验证。
- 案例：定长队列+拒绝策略稳定延迟。
- 速记：数据说话。

### 6.5 DCL 单例正确实现 [4]
- 是什么：延迟实例化。
- 为什么：节省启动与内存。
- 怎么用：volatile + 双检查 + sync；或 Holder/enum。
- 关键细节：构造重排风险。
- 常见陷阱：缺 volatile。
- 面试提示：字节码顺序说明风险。
- 速记：DCL 必 volatile；优先 Holder/enum。

### 6.6 本地锁 vs 分布式锁 [3]
- 是什么：进程内锁（synchronized/Lock）只能在单 JVM 内互斥；分布式锁依赖 Redis/ZooKeeper/DB 等实现跨进程互斥。
- 为什么：多实例部署时仅靠本地锁无法防止跨实例并发，如重复扣款、重复任务执行。
- 怎么用：本地共享状态用本地锁；跨实例关键操作通过业务幂等 + 分布式锁/去重表保护；实现分布式锁时关注过期、续约、可重入、失效安全。
- 关键细节：分布式锁只是辅助，幂等和约束（唯一索引）才是一致性的根本；时钟漂移、网络分区会影响锁可靠性。
- 常见陷阱：多机部署仍只用 synchronized 保护“全局唯一”逻辑；Redis 分布式锁实现不考虑超时续约与解锁原子性。
- 面试提示：在“秒杀/防重复下单”等题目中自动提到“幂等键 + 唯一约束 + 分布式锁”。
- 案例：支付回调被多次重复调用，通过订单号唯一约束 + 分布式锁保证最多一次生效。
- 速记：多机环境：先幂等，再谈锁。

### 6.7 并发下的事务与数据库一致性 [3]
- 是什么：数据库隔离级别、行级锁、乐观锁/悲观锁与应用层并发控制的组合。
- 为什么：很多并发问题表面在代码层，实质由数据库一致性与事务边界决定。
- 怎么用：对余额/库存等关键数据用行锁或版本号字段（乐观锁）；为关键约束添加唯一索引；根据场景选择合适的隔离级别与事务粒度。
- 关键细节：Repeatable Read/Read Committed 对幻读/不可重复读的影响；`select for update` 的锁范围；乐观锁失败后的重试与回退策略。
- 常见陷阱：只依赖应用层锁而忽略 DB 约束；事务范围过大导致锁竞争严重；乐观锁失败时无限重试。
- 面试提示：设计“库存扣减/秒杀”时，同时从应用锁、DB 锁和幂等几个维度回答。
- 案例：库存扣减只用本地锁，多实例部署后仍超卖；改为乐观锁 + 重试并配合唯一约束后问题解决。
- 速记：并发资金/库存：代码锁 + DB 约束双保险。

### 6.8 幂等性与重试策略 [4]
- 是什么：幂等：多次执行结果与一次相同；重试：在失败时安全地再次执行操作。
- 为什么：在网络抖动、服务抖动、并发重入时避免重复扣费/重复下单等严重问题。
- 怎么用：使用业务幂等 key（订单号、请求 ID）、唯一索引、乐观锁或去重表；为调用设置有限次数重试和退避策略，并确保操作设计为幂等。
- 关键细节：查询/写入/删除的幂等实现方式不同；重试需有上限和退避；部分操作需要“补偿”而非简单重试。
- 常见陷阱：声明接口“幂等”但仅靠缓存或本地 map；在网络超时时盲目重试导致重复下单。
- 面试提示：几乎所有支付/订单/消息投递类题目，都可以加一段“幂等+重试+补偿”的标准回答。
- 案例：支付回调多次触发，通过订单状态表 + 幂等 key，重复调用仅更新为同一状态，避免重复入账。
- 速记：高并发 + 不可靠网络 → 必谈幂等 + 重试。

## 七、性能与诊断工具

### 7.1 工具与指标 [4]
- 是什么：JFR、jstack、jmap、perf、async-profiler、ThreadMXBean。
- 为什么：缩短定位时间。
- 怎么用：自动采集；阈值告警；基线对比。
- 关键细节：GC 停顿与锁等待叠加；上下文切换过多。
- 常见陷阱：只看平均忽略 p99。
- 面试提示：列关键指标清单。
- 案例：火焰图定位锁竞争热区。
- 速记：JFR 低入侵；看 p99。

### 7.2 常见并发 Bug [4]
- 是什么：典型问题模式的集合，如竞态、死锁、活锁、饥饿、伪共享、错误发布、写偏等。
- 为什么：这些问题直接破坏正确性与性能，是并发系统最常见的隐藏雷区。
- 怎么用：识别模式后，针对性地使用上一章节的手段：用原子类替代 check-then-act；统一锁序避免死锁（细节见 6.3）；版本戳和乐观读 validate 防止写偏；通过结构重排降低伪共享等。
- 关键细节：活锁=不断退让无进展；饥饿=不公平调度或高优先级任务长期占用；伪共享可参考 8.1 的缓存行说明。
- 常见陷阱：只在日志中吞异常，掩盖竞态/死锁线索；把所有问题都归因于“JVM 有 bug”。
- 面试提示：准备 2~3 个真实案例，分别对应竞态、死锁/饥饿、伪共享，不必在此重复讲所有修复细节，引用对应章节编号即可。
- 速记：先识别模式，再对号入座用前面章节的解法。

### 7.3 并发测试：jcstress/JMH [3]
- 是什么：jcstress 验证语义；JMH 微基准。
- 为什么：防“看似正确”。
- 怎么用：预热+fork；显式校验；隔离 IO。
- 关键细节：死代码消除；基准场景单一变量。
- 常见陷阱：一次跑出结论。
- 面试提示：微基准与生产差异。
- 速记：验证语义→jcstress；测性能→JMH。

## 八、新特性与展望

### 8.1 伪共享与缓存行 [3]
- 是什么：同缓存行多线程写导致失效风暴。
- 为什么：总线流量↑吞吐↓。
- 怎么用：@Contended、分桶、填充。
- 关键细节：需 JVM 参数；过度填充浪费内存。
- 常见陷阱：无度量盲用 @Contended。
- 面试提示：计数器分桶示例。
- 案例：分桶计数 + @Contended p99 降 20%。
- 速记：高冲突→分离。

### 8.2 Structured Concurrency（展望）[2]
- 是什么：结构化任务作用域管理生命周期/取消/异常。
- 为什么：防止“孤儿任务”，简化汇总。
- 怎么用：StructuredTaskScope/ScopedValue。
- 关键细节：仍在演进；与线程池职责区分。
- 常见陷阱：与虚拟线程混淆。
- 面试提示：价值=统一取消与异常聚合。
- 速记：作用域化并发。
*** 子区：并发 vs 内存权衡 / 锁优化 / VarHandle / Disruptor / DCL / 并发测试 / Structured Concurrency / 线程池高级 / ThreadLocal / wait/notify / JUC 容器扩展 / CLQ / 线程池扩展 / 分布式锁 / 事务一致性 / 幂等 / ThreadLocalRandom

---

## 常见面试延伸追问与回答框架（扩展版，≥20题）

1. volatile 能替代锁做计数吗？不能，复合操作非原子。  
2. 双重检查锁为何需 volatile？防止重排序将引用提前暴露。  
3. ConcurrentHashMap 为什么迭代弱一致？降低全局加锁成本提升并发。  
4. LongAdder 什么时候不适合？需要实时精确读取或参与后续逻辑判断。  
5. synchronized 与 ReentrantLock 选择标准？需中断/超时/公平/条件队列则用 ReentrantLock，否则简单互斥用 synchronized。  
6. ReadWriteLock 写偏问题是什么？大量读锁占用导致写锁长期等待。  
7. StampedLock 乐观读如何验证？通过 stamp validate，失败回退悲观读锁。  
8. ForkJoinPool 阈值设置依据？拆分成本与任务处理时间比，避免过度细粒度。  
9. parallelStream 为什么不适合阻塞 IO？阻塞占用少量工作线程导致饥饿。  
10. CompletableFuture thenCompose 与 thenApply 区别？前者展开内部 future，后者仅映射结果值。  
11. 线程池核心参数估算方法？CPU 密集 core≈CPU；IO 密集 core≈CPU×(1+等待/计算比)。  
12. 为什么不推荐 Executors.newCachedThreadPool 滥用？无限增长线程可能耗尽资源。  
13. 死锁四条件及破坏方式？互斥/占有等待/不可剥夺/循环等待；破坏锁顺序或使用 tryLock 超时。  
14. CountDownLatch 与 join 区别？Latch 可等待任意任务集合，join 仅等待线程结束。  
15. Phaser 优势是什么？支持多阶段与动态注册参与者。  
16. 伪共享如何定位？性能分析发现高速写变量彼此干扰，缓存行命中率低。  
17. 为什么无竞争 synchronized 仍快？偏向/轻量级锁优化消除重量级阻塞。  
18. VarHandle 与原子类区别？提供更细粒度内存语义与对数组/字段统一访问抽象。  
19. Unsafe 不建议使用原因？非安全、可导致崩溃，兼容性差，受限权限。  
20. 虚拟线程与线程池差别？成本低，阻塞挂起不占平台线程，适合海量阻塞任务。  
21. RateLimiter 与 Semaphore 能否一起用？可以，先速率限制再并发限制。  
22. 为什么需要安全发布？避免其他线程看到部分初始化状态导致逻辑错误。  
23. computeIfAbsent 比双检更安全原因？单方法内原子语义避免竞态窗口。  
24. Lock 公平模式何时使用？防止饥饿，但吞吐降低，适合长持锁且需顺序公平场景。  
25. AQS 为什么使用自旋 + park？减少短期等待的阻塞开销，长等待再挂起。  
26. 为什么线程过多会降低吞吐？上下文切换和缓存失效开销增加。  
27. 如何检测生产死锁？ThreadMXBean.findDeadlockedThreads 定期扫描 + 告警。  
28. Actor 模型优势？消息串行保证不需锁，易于隔离状态。  
29. Disruptor 比 BlockingQueue 快的原因？环形缓冲预分配 + 序号屏障 + 减少伪共享。  
30. 什么时候选择 CopyOnWriteArrayList？读远多于写且列表较小，需稳定迭代。

---

## 重要度汇总
- JMM / happens-before [5]
- synchronized 与锁升级机制 [5]
- AQS 框架与实现原理 [5]
- ReentrantLock / ReadWriteLock / StampedLock [5]
- ConcurrentHashMap 深入与原子操作模式 [5]
- 线程池参数估算与调优 [5]
- volatile 使用边界 [5]
- 死锁预防与检测 [5]
- 原子类 / CAS / LongAdder [5]
- CompletableFuture 编排与异常处理 [4]
- ForkJoinPool / 工作窃取 [4]
- 虚拟线程 (Project Loom) [4]
- 并发设计模式与实践 [4]
- 安全发布 / 不可变对象 [4]
- 并发性能诊断与指标 [4]
- JUC 同步工具对比 (Semaphore/Latch/Barrier/Phaser) [4]
- CountDownLatch / Barrier / Phaser 语义区分 [4]
- 内存屏障与重排序 [3]
- 伪共享优化 [3]
- 并发与内存权衡 [3]
- JVM 锁优化机制 [3]
- VarHandle / Unsafe 语义 [3]
- Disruptor / RingBuffer [3]
- 并发测试 jcstress / JMH [3]
- RateLimiter vs Semaphore [3]
- Structured Concurrency 概念 [2]

 
---

## 附录：Spring 生态知识点分类索引（按领域+重要度）

说明：以下为《Spring生态详解.md》知识点的归类索引，括号为“(条目编号，[重要度])”。用于在并发专题外快速定位 Spring 相关能力点。

- 容器与装配（Core/IoC/Boot）
	- (1,[5]) BeanDefinition 与 IoC 容器；(2,[5]) Refresh 流程；(3,[5]) Bean 生命周期；(4,[5]) 两类后处理器；(5,[5]) 三级缓存与循环依赖
	- (6,[4]) 作用域与 ScopedProxy；(7,[4]) 条件化装配与 Profile；(8,[5]) @ConfigurationProperties 属性绑定
	- (9,[4]) FactoryBean；(10,[4]) ConversionService；(11,[4]) Bean 校验（JSR-303）
	- (44,[3]) Starter 设计；(45,[4]) 启动优化与懒加载；(47,[4]) 循环依赖重构；(35,[3]) Profiles 与环境隔离

- AOP 与事务（TX）
	- (12,[5]) AOP 代理模型；(13,[4]) 切点表达式；(14,[5]) @Transactional 原理
	- (15,[5]) 事务传播；(16,[4]) 隔离级别差异；(17,[3]) readOnly 优化
	- (46,[5]) 事务失效排查清单；(57,[3]) 分布式事务与补偿

- Web MVC（同步编程模型）
	- (21,[5]) 调用链与扩展点；(22,[4]) 参数绑定与类型转换；(23,[4]) 统一异常处理
	- (24,[4]) Filter/Interceptor/AOP 分层；(26,[4]) HttpMessageConverter 与协商

- WebFlux（响应式编程模型）
	- (25,[4]) WebFlux 模型/背压/阻塞适配

- 数据访问与持久化
	- (27,[4]) JPA 实体生命周期/缓存；(28,[4]) JPA 乐观锁
	- (29,[3]) MyBatis 动态 SQL；(30,[3]) MyBatis 拦截器链
	- (31,[4]) Spring Cache 抽象（击穿/穿透/并发）

- 可观测性与运维
	- (18,[4]) Actuator 端点；(19,[4]) Micrometer 指标；(20,[4]) 健康检查 Liveness/Readiness
	- (54,[4]) 追踪+日志+指标整合；(55,[3]) 链路追踪传播；(53,[4]) 排错思路/ConditionEvaluationReport

- 安全与认证授权
	- (36,[5]) 安全过滤器链与认证流程；(37,[4]) 方法级安全；(38,[4]) OAuth2/JWT
	- (59,[3]) 安全加固与敏感信息管理

- 异步与调度
	- (33,[4]) @Async 与上下文传播；(34,[3]) @Scheduled 与集群一致性
	- (48,[4]) Spring 场景下的线程安全/线程池隔离

- 云原生与微服务
	- (39,[3]) 服务发现与注册；(40,[3]) 配置中心与动态刷新
	- (41,[3]) Gateway 路由与过滤；(42,[3]) Feign 声明式客户端

- 稳定性与弹性治理
	- (43,[3]) Resilience4j（熔断/限流/重试/隔离）
	- (56,[3]) 限流与熔断组合策略；(58,[3]) 异步任务错误处理与退避重试

- 测试与工程实践
	- (49,[3]) Test Slice 分层测试；(50,[3]) Testcontainers 环境一致性
	- (51,[3]) 模块拆分与上下文控制；(52,[4]) 常见性能陷阱（扫描/反射/序列化/N+1）

提示：学习顺序建议先覆盖 [5]，再按项目场景补齐 [4]/[3]；遇到事务/并发/性能问题时优先查本索引对应条目。

(完)