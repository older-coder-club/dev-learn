# 计算机网络面试指南（资深 Java 工程师）

评分说明：5=必须掌握，4=很重要，3=熟练更佳，2=了解即可，1=加分项  
格式：每个知识点统一五段：是什么 / 为什么 / 怎么用 / 关键细节 / 面试提示。面试回答建议先给概念主线，再结合工程场景与排障示例。

---

## 1. 分层模型：OSI 与 TCP/IP [5]
是什么：OSI 七层是教学抽象；实际互联网协议栈常以 TCP/IP 四层（链路 / 网络(IP) / 传输(TCP/UDP) / 应用(HTTP 等)）为主，部分把链路再拆成物理+数据链路形成五层说法。  
为什么：分层让职责清晰，便于将问题定位到具体层面：链路错误（丢帧）与应用协议错误（序列化、语义）分离，减少排障范围。  
怎么用：排障思路自下而上（或自上而下）：先检查物理连接与链路（丢包、错误率），再看 IP 路由与地址，之后看 TCP 建连与重传，最后审应用日志与协议格式。设计时按层隔离变化（例如切换 HTTP/1.1→HTTP/2 不影响业务语义层）。  
关键细节：会话层/表示层在多数现代框架被应用层吸收；TLS 运行“介于”传输与应用之间；过度追求完整 OSI 七层会影响工程直觉。  
面试提示：说明为什么“四层模型更实用”：精简、不影响定位；给出“请求失败→Ping 通/握手失败/应用 4xx/序列化错误”分层排查路径。

## 2. 以太网、MAC 与 VLAN [3]
是什么：以太网二层使用 MAC 地址进行帧转发；交换机学习端口与 MAC 映射；VLAN 通过 802.1Q Tag 实现二层广播域逻辑隔离。  
为什么：理解广播域范围影响局域网ARP泛洪与安全隔离；多租户或多环境（生产/测试）隔离需 VLAN。  
怎么用：出现广播风暴或异常 ARP 流量时抓包分析；规划不同业务的 VLAN；诊断“跨 VLAN 无法访问”时检查三层路由与 TAG 配置。  
关键细节：广播地址 FF:FF:FF:FF:FF:FF；MTU 默认 1500，VLAN Tag 占 4 字节可能影响抓包判断；Trunk 端口允许多 VLAN 通过。  
面试提示：回答“跨 VLAN 为什么要路由器/三层交换”并能解释广播域缩小意义。

## 3. IP 地址、CIDR 与子网划分 [5]
是什么：IPv4 32 位地址通过 CIDR 前缀（如 /24）表达网络与主机部分；子网掩码决定可用主机数。  
为什么：错误的掩码或网关配置会导致“局域网内互通，跨网段失败”，影响服务发现与访问。  
怎么用：排查网络不可达时：确认本机 IP/Mask/网关；判断目标是否同网段（与本机 IP 按掩码与运算比较）；规划私有地址避免冲突。  
关键细节：私有网段范围：10/8, 172.16/12, 192.168/16；/26 = 64 地址，去掉网络与广播，可用 62；CIDR 前缀越大主机越少。  
面试提示：快速心算 /26 可用主机数展示基础扎实；可再加“错误掩码导致包发往默认网关绕行”。

## 4. ARP / NDP 地址解析 [4]
是什么：ARP 将 IPv4 地址解析为 MAC；IPv6 使用 NDP（邻居发现协议）完成类似功能并扩展自动配置。  
为什么：首次访问某主机出现轻微延迟多是 ARP/NDP 的解析过程；ARP 欺骗可导致流量劫持。  
怎么用：使用 arp -a 查看缓存；异常延迟或重定向检查是否 ARP 污染；多次错误 MAC 映射需清理缓存。  
关键细节：ARP 缓存有老化时间；广播询问后目标回复单播；ARP 欺骗构造错误映射让网关流量重定向。  
面试提示：解释“首次访问延迟原因”和“ARP 欺骗危害与防护（静态条目、DHCP Snooping）”。

## 5. 路由与转发 / 静态与动态 [3]
是什么：路由表决定下一跳；静态路由是人工配置；动态路由协议（OSPF/BGP）基于拓扑或策略自动更新。  
为什么：多网段、跨地域或多出口场景需要正确路由，否则出现“Ping 内网正常，跨网失败”。  
怎么用：查看本机路由（ip route / route -n）；多宿主（双网卡）时检查策略路由；跨云或跨机房使用 BGP 做自治域间 。  
关键细节：最长前缀匹配（更具体路由优先）；默认路由 0.0.0.0/0；策略路由可按源地址或标记进行转发。  
面试提示：回答“为什么更长前缀被优先匹配”表明理解路由匹配原则。

## 6. TCP 三次握手与四次挥手 [5]
是什么：握手 SYN→SYN+ACK→ACK 建立连接；挥手 FIN→ACK→FIN→ACK 关闭连接。  
为什么：验证双方收发能力与初始化序列号；挥手分离半关闭，处理缓冲未读数据；理解 TIME_WAIT/CLOSE_WAIT 排障。  
怎么用：抓包确认握手失败（SYN 重传）；大量短连接导致 TIME_WAIT 积累需连接池或复用；CLOSE_WAIT 长期存在多为应用未关闭 socket。  
关键细节：主动关闭方进入 TIME_WAIT 等待 2MSL；ISN 随机防注入攻击；半开连接可能被内核清理。  
面试提示：解释“为何主动关闭易出现 TIME_WAIT”与“如何通过 SO_REUSEADDR/长连接缓解”。

## 7. TCP 流量控制与拥塞控制 [5]
是什么：流量控制：滑动窗口避免接收端缓冲溢出；拥塞控制：调节发送速度适应网络（慢启动、拥塞避免、快速恢复、Cubic/BBR）。  
为什么：决定实际吞吐；优化高带宽+长 RTT（跨洋）链路依赖正确算法与窗口调参。  
怎么用：监控窗口大小缩小判断接收端处理慢；启用 BBR 在 Linux 内核提升传输效率；分析丢包与重传是否拥塞而非主机性能瓶颈。  
关键细节：慢启动指数膨胀到阈值后线性增长；丢包信号触发拥塞窗口下调；BBR 基于带宽与 RTT 建模而非只靠丢包。  
面试提示：比较“传统丢包驱动 vs BBR 模型驱动”并指出适用场景。

## 8. TCP 可靠性：序列号、ACK、重传与 RTO [5]
是什么：通过序列号标识数据顺序；ACK 确认已收到；丢包通过重传机制恢复；RTO（重传超时）退避防过度发送。  
为什么：丢包与重传激增会造成延迟尖峰和吞吐下降，需要区分网络问题还是服务端过载。  
怎么用：抓包看重复 ACK（表明快速重传触发）；分析 RTO 超时与退避是否异常；调节内核参数（如 net.ipv4.tcp_retries2）。  
关键细节：快速重传：收到 3 个重复 ACK 立即重传；SACK（选择性确认）提高效率；RTO 动态根据 RTT 估算。  
面试提示：清晰描述“快速重传触发条件与作用”。

## 9. TCP 优化特性：Nagle、延迟 ACK、Keepalive [4]
是什么：Nagle 合并小包减少报文；延迟 ACK 等待是否可以一起确认；Keepalive 检测闲置连接存活性。  
为什么：未理解会造成“交互型 RPC 小消息莫名 200ms 延迟”或无效长连接占用资源。  
怎么用：交互小消息禁用 Nagle（TCP_NODELAY）；观察延迟 ACK 是否影响请求-响应往返；设置合理 Keepalive 间隔以清理死链。  
关键细节：Nagle+延迟 ACK 组合导致额外交互延迟；Keepalive 默认间隔很长（多小时）；禁用特性需权衡带宽。  
面试提示：能说出“为什么要关 Nagle”的具体场景（聊天、交易轻量请求）。

## 10. UDP 特性与应用场景 [4]
是什么：无连接、不可靠、无内建拥塞控制或重传的报文传输协议。  
为什么：实时、对少量丢包不敏感或自定义恢复策略的场景（音视频、游戏、DNS）更合适。  
怎么用：在应用层添加序列号/重传/校验/拥塞策略；选择合适 MTU 避免分片；对打洞操作使用 STUN/TURN。  
关键细节：可能乱序/丢包；放大攻击需限制响应策略；没有握手降低初始延迟。  
面试提示：说明“UDP 优势并非永远更快，可靠场景仍需 TCP 或 QUIC”。

## 11. QUIC 与 HTTP/3 基础 [4]
是什么：运行在 UDP 上的传输层协议，集成加密、拥塞控制、多路复用和连接迁移，HTTP/3 构建在 QUIC 之上。  
为什么：解决 TCP+TLS+HTTP/2 组合握手往返多、队头阻塞和移动网络切换 IP 时断连问题。  
怎么用：启用服务端 HTTP/3；评估客户端支持率；保留 HTTP/2 回退；监控新握手失败与迁移成功率。  
关键细节：0-RTT 减少往返但有重放风险；每条流独立不因单个丢包阻塞全部；连接标识不依赖四元组。  
面试提示：对比“TCP 丢包影响所有 HTTP/2 流 vs QUIC 只影响单流”。

## 12. HTTP/1.1 机制与性能痛点 [5]
是什么：基于文本的请求/响应协议，使用请求行+头+正文；支持 Keep-Alive 长连接但存在队头阻塞。  
为什么：理解其局限可解释为何需要 HTTP/2/3；优化仍大量遗留系统性能。  
怎么用：压缩响应（GZIP/Brotli）；合理使用缓存头；减少 Cookie 体积；尽量复用连接。  
关键细节：管线化不被广泛实现；头重复冗余；队头阻塞：同一连接后续请求等待前一个完成。  
面试提示：说明“旧做法将静态资源拆域名是为并行连接”历史背景。

## 13. HTTP/2 改进与限制 [5]
是什么：用二进制帧、多路复用、头部压缩（HPACK）与优先级机制改善 HTTP/1.1。  
为什么：单连接多流减少握手与队头阻塞（应用层），提升带宽利用率。  
怎么用：开启服务端支持；监控流并发与头压缩命中；避免巨型 Cookie/头影响压缩率。  
关键细节：TCP 丢包仍使所有流等待恢复（传输层队头阻塞残留）；优先级可能被忽略；过多并发流造成内存与调度开销。  
面试提示：指出“队头阻塞在传输层仍未彻底解决”引出 HTTP/3。

## 14. HTTP/3 / QUIC 优势总结 [4]
是什么：将多路复用与加密融合在 UDP 基础上，连接迁移支持 IP 变化不重建连接。  
为什么：移动网络切换、弱网络丢包场景改善明显；简化握手减少延迟。  
怎么用：灰度开启；分析握手成功率与回退比例；观察丢包情况下尾延迟。  
关键细节：0-RTT 重放风险需限制幂等接口；中间盒不识别 UDP 导致兼容问题；自定义拥塞算法演进快。  
面试提示：描述“客户端从 Wi-Fi 切到 4G 不中断长连接”的价值。

## 15. WebSocket / SSE / 长轮询 [3]
是什么：WebSocket 基于升级握手建立双向全双工；SSE 单向服务器推送文本事件；长轮询通过客户端保持挂起请求模拟实时。  
为什么：各自取舍：双向复杂交互→WebSocket；仅服务器推送→SSE；不支持两者场景→降级长轮询。  
怎么用：设置心跳与断线重连；控制消息大小与节奏；处理背压（客户端慢写）。  
关键细节：代理与负载均衡对升级握手支持需验证；SSE 仅文本与自动重连；长轮询资源浪费。  
面试提示：比较三者并给出“行情推送与 Chat 场景选型”。

## 16. gRPC 与二进制协议 [4]
是什么：基于 HTTP/2 的高效 RPC 框架，使用 Protobuf 进行紧凑结构化序列化，支持双向流与拦截器。  
为什么：比 JSON REST 更低带宽与解析成本，适用于服务间高 QPS 调用与流式数据。  
怎么用：定义 proto→生成代码→实现服务→配置拦截器（鉴权、日志）→监控延迟与流量。  
关键细节：默认压缩头与多路复用；调试需特殊工具；字段编号影响兼容；双向流需控制内存与背压。  
面试提示：说明“内部接口需要高性能与流式 → 选 gRPC”的标准。

## 17. TLS 握手、会话与证书验证 [5]
是什么：客户端与服务器完成握手协商算法、交换密钥（前向安全），验证证书链后建立对称加密会话。  
为什么：保证机密性、防中间人、数据完整性；TLS1.3 降低往返提高建立速度。  
怎么用：使用现代套件（ECDHE+AES-GCM/CHACHA20），启用 TLS1.3；自动化证书续期；开启 OCSP Stapling 减少在线验证延迟。  
关键细节：前向安全避免密钥泄漏后解密历史流量；SNI 支持多域名；会话复用/票据减少重复握手。  
面试提示：解释“TLS1.3 减少握手往返 + 更安全”并举例其对首字节延迟优化。

## 18. TLS 优化与安全实践 [4]
是什么：通过会话缓存/票据、0-RTT、合理套件与密钥轮换降低延迟与风险。  
为什么：频繁短连接或高并发握手场景可显著降低 CPU 与延迟。  
怎么用：启用会话复用；选择安全套件；定期轮换密钥；限制 0-RTT 对非幂等请求；监控失败率。  
关键细节：0-RTT 可重放，需服务端策略判定；弃用旧协议（TLS1.0/1.1）；密钥长度与性能权衡。  
面试提示：指出“0-RTT 不是免费加速，需防重放”。

## 19. DNS 解析与缓存层次 [4]
是什么：递归 DNS 查询通过本地缓存→上级缓存→权威服务器链路获取记录；TTL 控制缓存失效。  
为什么：高频域名解析延迟影响首包；灰度/切流需要低 TTL 加快变更生效。  
怎么用：设置合理 TTL 不过低（防止频繁回源）；多地域使用智能解析返回就近节点；监控 QPS 与失败率。  
关键细节：DNS 污染/劫持可能返回错误 IP；TTL 太低增加解析成本；缓存层次浏览器→OS→递归服务器。  
面试提示：说明灰度策略需降低 TTL，并提及“缓存传播延迟”。

## 20. 负载均衡：四层与七层及算法选择 [5]
是什么：四层基于传输层（TCP/UDP）不解析应用数据；七层解析 HTTP 等内容做更细粒度路由；算法包括轮询、权重、最少连接、一致性哈希等。  
为什么：影响扩展能力、会话保持与路线智能性；一致性哈希缓解有状态存储热点迁移。  
怎么用：无状态服务优先四层提升吞吐；需要基于路径/头/内容分流用七层；状态依赖用一致性哈希或会话粘性。  
关键细节：健康检查策略（TCP/HTTP/API）；热点 Key 倾斜需再均衡；一致性哈希增加虚拟节点改善分布。  
面试提示：给出“用户会话分片到缓存节点”使用一致性哈希场景。

## 21. 反向代理、缓存与 CDN [4]
是什么：反向代理接收外部请求转发后端；缓存静态与可重用响应；CDN 在边缘节点分发降低延迟。  
为什么：减轻源站压力、提升全球访问与带宽利用率。  
怎么用：配置 Cache-Control/ETag；使用对象哈希文件名实现长缓存；CDN 回源鉴权和刷新策略。  
关键细节：强缓存与协商缓存区别；Brotli 比 GZIP 更佳压缩率但 CPU 更高；失效策略防止旧内容滞留。  
面试提示：说明“强缓存命中无需往返，协商缓存仍需一次条件请求”。

## 22. NAT、端口映射与连接跟踪 [3]
是什么：NAT 将私网地址转换为公网地址；连接跟踪表维护会话状态；端口映射允许外网访问内部服务。  
为什么：私网地址复用节省地址空间；对长连接系统连接跟踪表耗尽是风险。  
怎么用：为需要外部访问的服务设置端口转发；监控 conntrack 表使用；对 P2P 场景考虑打洞策略。  
关键细节：表满时新连接失败；Symmetric NAT 穿透困难；长时间空闲连接可能被回收。  
面试提示：解释“NAT 对高并发长连接的限制与解决（减少多余连接、保持活动）”。

## 23. MTU、分片与路径 MTU 发现 [3]
是什么：MTU 是链路最大帧大小；超过会分片（IP 层）或由发送端调整；PMTUD 通过探测 ICMP 返回发现路径最小 MTU。  
为什么：分片增加丢包风险与重组开销；大包丢失需重传整个。  
怎么用：控制应用层报文大小；避免单个 UDP 大包；若 ICMP 被阻断导致 PMTUD 失败需强制使用较小 MTU。  
关键细节：DF 标志阻止分片；ICMP 过滤导致黑洞；分片任何一个丢失需重传整体。  
面试提示：说明“大包一次丢失比多个小包更痛”的原因。

## 24. TCP 状态与 TIME_WAIT / CLOSE_WAIT 排查 [4]
是什么：TCP 状态机体现连接生命周期；TIME_WAIT 等待残留包安全消失；CLOSE_WAIT 表示对端已关闭本端未关闭。  
为什么：大量 TIME_WAIT 占用端口影响新连接；CLOSE_WAIT 堆积表示资源未释放。  
怎么用：ss/netstat 统计状态数量；启用连接池减少频繁建立；检查业务代码是否正确关闭输入流与 Socket。  
关键细节：TIME_WAIT 持续 2MSL；CLOSE_WAIT 常因未调用 close；可调内核重用策略但需注意风险。  
面试提示：给出“CLOSE_WAIT 原因→未关闭输入流→修复”具体案例。

## 25. 网络安全：DDoS、WAF、防火墙、IDS [3]
是什么：DDoS 大流量耗尽资源；WAF 过滤应用层攻击（SQL 注入/XSS）；防火墙基于端口/IP 规则；IDS 检测入侵行为。  
为什么：保障可用性与数据安全；错误配置可能误杀合法流量。  
怎么用：设置速率限制、黑白名单；联合 CDN/清洗服务；审计 WAF 告警。  
关键细节：应用层慢速攻击（Slowloris）不是纯带宽；WAF 规则更新频率；误报与漏报权衡。  
面试提示：区分“带宽耗尽型 vs 应用层慢请求攻击”的防护策略。

## 26. 加密与认证：TLS vs OAuth2 [3]
是什么：TLS 保障传输加密与完整性；OAuth2 处理用户授权与访问令牌分发；身份验证与加密职责不同。  
为什么：仅有 TLS 不能证明调用者身份或权限；误以为“HTTPS 就安全全套”。  
怎么用：HTTPS 全站；OAuth2 使用短期 Access Token + Refresh Token；敏感操作加服务端校验。  
关键细节：JWT 失效与撤销难题；Scope 最小授权；Token 泄露攻防。  
面试提示：强调“加密不等于认证+授权”并简述组合方式。

## 27. HTTP 缓存策略与条件请求 [4]
是什么：强缓存（Cache-Control/Expires）直接命中；协商缓存（ETag/Last-Modified）需验证后决定 304 或返回新内容。  
为什么：减轻带宽与后端压力；提高响应速度；版本化发布控制失效。  
怎么用：静态资源长缓存+文件名哈希；API 谨慎设置缓存头；ETag 基于内容散列或版本号。  
关键细节：no-store 不缓存；no-cache 需再验证；ETag 冲突导致缓存失效；分布式部署需一致生成策略。  
面试提示：说明“文件指纹+长缓存+回滚策略”的组合。

## 28. CORS、同源策略与 CSRF [3]
是什么：同源策略限制脚本跨域读写；CORS 标头允许受控跨域；CSRF 利用已登录状态发起伪请求。  
为什么：避免错误跨域放开导致数据泄露；防止用户未察觉恶意操作。  
怎么用：按需设置 Access-Control-Allow-Origin（不盲目 * 对带认证请求）；使用 CSRF Token 或 SameSite Cookie。  
关键细节：预检 OPTIONS；简单请求条件；Referrer 与 Origin 差异；POST JSON 常触发预检。  
面试提示：解释“为什么出现 OPTIONS 预检”及“如何避免不必要跨域风险”。

## 29. Java 网络编程：BIO、NIO、Netty [5]
是什么：BIO 一连接一线程阻塞式；NIO 使用 Selector 多路复用减少线程；Netty 封装事件驱动、内存池、编解码与背压。  
为什么：高并发长连接下 BIO 线程数量爆炸与上下文切换成本高；NIO/Netty 提升吞吐与资源效率。  
怎么用：采用 Netty ChannelPipeline 组合 Handler；设置合适 boss/worker 线程数；使用 ByteBuf 管理堆内/直接内存；处理背压时暂停读或队列限速。  
关键细节：Selector 空轮询 Bug（JDK 老版本）；DirectBuffer 释放延迟；编解码器顺序影响协议正确性；避免单 Handler 做长耗时阻塞。  
面试提示：回答“为什么改造后 CPU 与内存占用下降”并提及“线程数与上下文切换减少”。

## 30. 背压、流控与高并发保护 [4]
是什么：系统在下游压力大时主动减速或拒绝请求（限流/排队/丢弃），防止级联崩溃。  
为什么：无背压高峰期会挤爆队列与线程池，引发雪崩与持续尾延迟。  
怎么用：设定队列最大长度与等待时间；令牌桶限制峰值；使用响应降级（返回缓存/默认值）；Reactive Streams 标准协商请求速率。  
关键细节：重试放大会恶化拥塞；分级限流（核心 vs 非核心接口）；监控拒绝率与等待时长。  
面试提示：描述一次“线程池饱和→限流+快速失败”成功防护案例。

## 31. 抓包与排障工具链 [5]
是什么：tcpdump/Wireshark 抓包；ss/netstat 查看连接状态；traceroute/mtr 路径与丢包；dig DNS；curl/wrk 压测；结合日志与指标定位。  
为什么：网络故障隐蔽（丢包/重传/握手失败），需精确抓取证据避免猜测。  
怎么用：过滤条件（tcpdump 'port 8080 and tcp'）；分析三次握手时间；查看重复 ACK 与窗口大小；路径跟踪确认中间路由节点问题。  
关键细节：抓包有开销；TLS 加密需会话密钥方可还原应用数据；mtr 持续测试丢包稳定性；不要在高流量下无过滤抓包。  
面试提示：给出“延迟升高→抓包→发现大量重传→定位网络链路抖动”的结构化过程。

## 32. 延迟与吞吐调优维度 [4]
是什么：延迟关注单次响应时间（平均、P95/P99）；吞吐关注单位时间处理数量；两者优化策略不同。  
为什么：只提升吞吐可能损害尾延迟；只压低延迟可能降低整体利用率。  
怎么用：区分冷启动延迟与稳定状态；为批处理任务允许较高延迟换更高吞吐；针对交互型接口优先优化 P99。  
关键细节：排队等待是尾延迟主要来源；降低上下文切换与 GC 停顿对尾延迟有效；吞吐由 CPU 利用率与并发度决定。  
面试提示：举“批量发送 vs 单条实时”场景说明取舍。

## 33. 尾延迟 (P99/P999) 控制 [3]
是什么：高百分位延迟代表最慢请求体验；决定 SLO 是否可被满足。  
为什么：平均值忽略尖峰，用户感知主要由尾部决定；金融/交易等需稳定尾延迟。  
怎么用：识别慢路径（数据库慢查询、锁等待、GC）；使用熔断或隔离线程池防扩散；缓存热点数据。  
关键细节：尾延迟经常由少量资源竞争或 IO 抖动造成；避免长批任务占用通用线程池；剔除异常冷启动样本。  
面试提示：说明一次优化尾延迟的具体手段（索引+隔离线程池）。

## 34. CDN 与边缘加速 [3]
是什么：CDN 在全球多个边缘节点缓存静态或半动态内容，用户从最近节点获取。  
为什么：降低时延与回源负载；提升海外或跨地域访问体验。  
怎么用：缓存长效资源（版本化静态文件）；对私有或鉴权资源加签名与过期控制；预热发布前热点路径。  
关键细节：动态个性化内容难缓存；回源失败降级策略；缓存失效需精准刷新避免全量清空。  
面试提示：区分“可缓存静态 vs 不易缓存动态”并给缓存失效策略。

## 35. 序列化与网络传输格式 (JSON / ProtoBuf) [3]
是什么：JSON 文本人类可读；ProtoBuf 二进制紧凑，字段编号驱动结构。  
为什么：内部高 QPS 服务注重效率与带宽；外部 API 注重可读性与灵活性。  
怎么用：内部 RPC 用 ProtoBuf/gRPC；对外 REST 用 JSON；大型对象按需压缩；注意字段兼容（ProtoBuf 不删除使用中的标签）。  
关键细节：JSON 解析成本高且冗余字段名；ProtoBuf 向后兼容：新增字段不破坏旧客户端；压缩与序列化顺序影响 CPU。  
面试提示：回答“为什么内部改用 ProtoBuf”并提体积与 CPU 优势。

## 36. Web 性能优化：连接复用、压缩与缓存 [3]
是什么：利用协议特性和缓存策略减少往返数与字节数，加快页面与接口响应。  
为什么：直接影响用户体验与服务器资源成本；尾延迟与首屏时间关键。  
怎么用：启用 HTTP/2/3 多路复用；压缩文本（Brotli/GZIP）；利用浏览器缓存与服务端缓存；减少阻塞资源（关键 CSS/JS）。  
关键细节：过度合并资源在 HTTP/2 下可能反而增加缓存失效范围；Brotli 压缩比高但更耗 CPU；ETag 结合指纹文件。  
面试提示：列举“三项快速见效：开启 HTTP/2、静态资源指纹长缓存、按需压缩”。

---

### 重要度速览
- 5：分层模型 / TCP 握手与关闭 / 流量+拥塞 / 可靠性 / HTTP/1.1 & HTTP/2 / TLS 握手 / Netty/NIO / 抓包排障
- 4：DNS / 负载均衡 / QUIC/HTTP3 / UDP / HTTP 缓存 / TLS 优化 / 背压 / TIME_WAIT 分析 / Java 网络延迟调优
- 3：VLAN/MAC / 路由基础 / MTU 分片 / WebSocket/SSE / gRPC / CORS/CSRF / CDN / 序列化格式 / 尾延迟 / Web 性能
- 2：ARP 深细节 / NAT 高级 / io_uring 前瞻 / 高级拥塞调参 / 安全设施细节
- 1：极少用底层协议定制

### 面试高效回答结构建议
1. 先总线：客户端请求→DNS→TLS 握手→连接复用→应用协议→负载均衡→服务内部 RPC。  
2. 再性能：从拥塞控制、队头阻塞、序列化、缓存与背压层层递进。  
3. 最后故障案例：丢包重传→窗口缩小→抓包验证→调整或切换线路。

(完)