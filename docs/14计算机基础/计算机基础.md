# 计算机基础（体系结构 / 操作系统 / Linux）面试指南（强化版）

评分说明：5=必须掌握，4=很重要，3=熟练更佳，2=了解即可，1=加分项  
结构：统一“是什么 / 为什么 / 怎么用 / 关键细节 / 面试提示”五段，要求能在面试中层层下钻。尽量一条只聚焦一个核心知识点，避免混杂。

---

## 1. CPU 缓存层级与局部性 [5]
是什么：现代 CPU 采用多级缓存层次（L1 指令/数据、L2、共享 L3，部分还有 LLC），通过时间局部性（最近访问的再次访问概率高）与空间局部性（相邻内存访问集中）减少访问主内存（几十到上百 ns）的高延迟。  
为什么：理解缓存行为是高性能 Java 的底座；选择数组连续存储远优于链表指针跳转；错误的数据布局会放大跨核一致性流量（缓存行频繁失效）。  
怎么用：设计数据结构时优先紧凑连续（结构体/数组）；批量聚合处理减少随机访问；遍历二维数组按行（与内存布局一致）；减少频繁写共享对象的多个字段；统计类使用分片或 LongAdder 分散竞争。  
关键细节：缓存行一般 64B；伪共享=不同线程写同一行不同变量触发反复失效；写回/写直达策略；指针链造成大量 TLB + 缓存 miss；GC 对对象位置整理也影响局部性。  
面试提示：举一个“多线程写数组相邻槽位导致性能抖动”→解释伪共享→给出填充或 @Contended 解决。

## 2. 缓存一致性协议 (MESI) 与内存屏障 [5]
是什么：MESI 协议用四种状态（Modified/Exclusive/Shared/Invalid）维护多核缓存行一致；内存屏障防止 CPU 和编译器重排破坏并发语义。Java volatile/锁底层通过特定指令（如 lock 前缀、fence）实现屏障。  
为什么：正确使用 volatile/原子类需要理解可见性与有序性；否则可能出现“写入另一个线程可见但顺序错乱”或“自增非原子”。  
怎么用：发布对象：构造完成后再写入共享引用；复合操作（读-改-写）用 CAS 或锁；减少写共享可在局部变量汇总后一次写回；读多写少使用不可变对象。  
关键细节：volatile 写具“释放”语义，读具“获取”语义；StoreLoad 屏障最强；指令重排不改变单线程语义但影响跨线程执行顺序；双重检查单例必须用 volatile。  
面试提示：回答“volatile 为何不保证 ++ 原子性”并说明需使用 AtomicLong 或 synchronized/CAS。

## 3. 指令流水线与分支预测 / 乱序执行 [3]
是什么：流水线把取指、译码、执行、写回阶段重叠；分支预测提前猜测分支方向避免停顿；乱序执行提升执行单元利用率同时保证提交次序正确。  
为什么：高频条件分支预测失败会清空流水线；理解这一点指导减少难预测的分支（数据相关或高度随机）。  
怎么用：热路径里用查表/位运算代替嵌套 if；减少基于 volatile 状态频繁改变的分支；必要分支放在不那么频繁执行的分支外层。  
关键细节：预测失败=流水线 flush；硬件保持“内存模型”允许重排但由语言内存模型（JMM）约束；过多条件级联增加 BTB 压力。  
面试提示：举“频繁随机布尔分支导致性能下降”→说明预测命中率影响。

## 4. NUMA 架构与内存亲和 [3]
是什么：多插槽或多节点服务器内存分为多个 NUMA 节点，本地内存访问延迟低，跨节点访问（远程）延迟高。  
为什么：大堆、多线程或内存密集任务若频繁远程访问会出现抖动与吞吐低下；GC 扫描远程页成本更高。  
怎么用：限制关键线程绑至节点（taskset/numactl）；避免把高交互线程分散到不同 NUMA 节点；对象集中分配减少跨节点写。  
关键细节：远程访问延迟可能扩大 2~3 倍；Linux 可按内存策略选择本地优先或跨节点均衡；JVM 对大堆在 NUMA 上有自适应策略有限。  
面试提示：描述“单线程在多 NUMA 节点频繁跨节点内存访问”导致的性能掉队与解决（线程绑核+数据分区）。

## 5. 虚拟内存 / 分页 / TLB [5]
是什么：虚拟地址通过多级页表映射物理页；TLB 缓存页表项加速翻译；缺页触发页面换入甚至 swap。  
为什么：大量随机访问大数据结构易出现 TLB miss 与缺页中断；理解可指导数据结构布局与是否启用 HugePages。  
怎么用：结构紧凑减少跨页；预热数据避免首次访问缺页；大对象集合可考虑分块；评估 HugePages 降低页表层级（谨慎与 GC 相互作用）。  
关键细节：4K 常规页、2M/1G HugePages；TLB 容量有限—过度稀疏访问导致命中率下降；mmap 加载文件映射可减少用户态缓冲复制。  
面试提示：解释“HashMap 扩容后访问延迟上升”与地址分散造成 TLB miss。

## 6. 零拷贝与内存映射 (sendfile / splice / mmap) [5]
是什么：利用内核缓冲复用，避免用户态/内核态双重复制（sendfile、FileChannel.transferTo、splice），mmap 将文件页直接映射进进程地址空间。  
为什么：高吞吐文件传输、日志、消息队列场景减少 CPU 使用与上下文切换，提升传输效率。  
怎么用：下载/文件传输使用 sendfile；Kafka 使用 transferTo；索引文件/只读元数据用 mmap；管道转发使用 splice。  
关键细节：mmap 文件扩展导致 SIGBUS 风险；TLS 场景 sendfile 需额外加密缓冲处理；PageCache 压力需监控（缓存污染）。  
面试提示：区分“零拷贝不是绝对不拷贝，是减少数据跨用户态与内核态复制”。

## 7. 进程 / 线程模型与上下文切换 [5]
是什么：进程具有独立地址空间与资源；线程共享进程内存；上下文切换保存和恢复寄存器、栈指针、部分缓存/TLB 状态。  
为什么：线程过多导致调度开销、CPU 缓存污染与内存占用增加；不合理线程池配置直接影响吞吐与延迟。  
怎么用：CPU 密集线程数≈核心数或核心数+1；IO 密集按阻塞比例估算（线程数=核心数/(1-阻塞比)）；用池减少频繁创建销毁；避免线程长时间阻塞占位。  
关键细节：pidstat cswch/nvcswch 可观察切换；Lock 竞争导致 runnable 堆积但不一定高 CPU；频繁短任务可用协程框架（虚拟线程）进一步降低切换。  
面试提示：给出“从 300 线程降到 64 提升吞吐”案例说明切换成本。

## 8. Linux 调度 (CFS) 与优先级 [4]
是什么：CFS（完全公平调度）用红黑树按虚拟运行时间 vruntime 选下一个运行任务；nice 值调整权重影响时间片。  
为什么：不理解调度机制易导致关键线程饥饿或后台任务抢占影响延迟。  
怎么用：避免滥用负 nice（提升优先级）；定位长时间得不到 CPU 的线程；监控 runnable 队列长度；对于高优先任务单独池隔离。  
关键细节：阻塞线程脱离红黑树；频繁唤醒线程有调度开销；cgroup 可进一步限制 CPU 配额。  
面试提示：解释“为何一个线程一直延迟执行”→可能 vruntime 相对落后+频繁被其它任务抢占。

## 9. 系统调用与用户 / 内核态切换 [4]
是什么：应用通过 syscall 进入内核执行 I/O、资源管理；切换涉及模式转换与上下文保存。  
为什么：高频小粒度 syscall（频繁 read/write/fsync）会拖慢整体性能；阻塞 syscall 导致线程挂起。  
怎么用：批量写入缓冲；使用 NIO 聚合 I/O；零拷贝减少读→写复制；减少频繁 flush；使用异步 I/O（AIO/io_uring，视支持度）。  
关键细节：strace 追踪系统调用；syscall 数量与每次开销（纳秒到微秒级）；TCP 小包写+Nagle/延迟 ACK 增加往返。  
面试提示：列举“降低系统调用次数”策略并说明收益。

## 10. I/O 模型与 epoll 多路复用 [5]
是什么：包括阻塞、非阻塞、IO 多路复用（select/poll/epoll）、异步事件驱动；epoll 提供高效监听大量 fd 的就绪事件。  
为什么：为高并发网络服务避免“一连接一线程”带来的资源浪费；核心在减少线程阻塞与切换。  
怎么用：使用 Netty 统一 Reactor；边缘触发时循环读取直到返回 EAGAIN；避免在 IO 回调中执行长阻塞逻辑；拆分编解码与业务处理。  
关键细节：select/poll 线性扫描 vs epoll 基于事件；水平触发重复通知，边缘触发需要彻底消费缓冲；惊群问题通过单一 accept 线程或 SO_REUSEPORT 策略调优。  
面试提示：解释“为什么数万连接仍保持少量线程”体现 epoll 原理理解。

## 11. 文件系统与页缓存 [4]
是什么：文件系统（如 ext4/XFS）管理 inode、目录与数据块；页缓存缓存文件数据以加速读写，脏页写回保证持久化。  
为什么：日志/顺序写吞吐与随机读写延迟差异根源；不理解可能误判 IO 性能瓶颈。  
怎么用：顺序追加日志减少寻址；需强一致时批量控制 fsync；数据库场景用 O_DIRECT 避免双缓存；监控脏页比例与写回频率。  
关键细节：延迟分配策略降低碎片；随机小写导致放大寻址与写放大；页缓存压力高引起频繁回收与抖动。  
面试提示：说明“随机写慢的根本原因”→寻址+缺乏顺序预读。

## 12. 进程间通信 (IPC) [3]
是什么：进程之间通过管道、消息队列、共享内存、Unix Domain Socket、信号等机制交换数据。  
为什么：不同 IPC 特性（吞吐、延迟、可靠性）决定在微服务或本地多进程模块间选型。  
怎么用：大吞吐低延迟用共享内存+环形缓冲；控制命令用 Unix Domain Socket；需要队列语义用消息队列/内核队列；信号用于轻量控制。  
关键细节：共享内存需同步（锁或原子操作）；Unix Socket 性能优于 TCP 回环；消息队列可能额外内核拷贝。  
面试提示：比较“共享内存 vs 管道”说明带宽与延迟差异。

## 13. cgroups / Namespaces 容器资源隔离 [4]
是什么：cgroups 进行 CPU/内存/IO/进程数限制；Namespaces 隔离 PID/网络/挂载/UTS 等环境，实现容器虚拟化。  
为什么：防止单服务占用全部资源导致系统雪崩；影响 JVM 自动堆与并行线程参数。  
怎么用：合理设置 memory.limit_in_bytes；CPU quota 影响并行 GC；监控 OOM killer 日志；必要时关闭过度限制避免频繁 GC。  
关键细节：新 JVM 能识别 cgroup 资源并调整堆；低内存限制导致频繁 Full GC；网络 namespace 影响端口与路由。  
面试提示：解释“为何容器内堆比宿主机物理内存小得多”并描述机制。

## 14. 内存泄漏与定位 (JVM / Native) [4]
是什么：对象或 native 资源（直接内存、文件句柄）未释放，持续占用导致堆膨胀或操作系统资源耗尽。  
为什么：会触发频繁 GC、OutOfMemoryError 或性能退化；定位难度高需系统化工具。  
怎么用：捕获 Heap Dump 用 MAT/VisualVM 分析保留路径；直接内存用 jcmd + NMT 或工具观察；检查 ClassLoader 循环引用、线程未结束、ByteBuffer 未释放。  
关键细节：DirectBuffer 回收依赖 Cleaner 触发时间不确定；ClassLoader 上下文缓存引用导致无法卸载；定时任务线程池泄漏。  
面试提示：举“Netty ByteBuf 未 release 导致直接内存飙升”完整排查过程。

## 15. 伪共享与缓存行填充 [4]
是什么：多个线程写入不同变量但共享一个缓存行，导致缓存行频繁失效与回写，大幅降低并发写性能。  
为什么：高频统计或计数器场景极易遭遇；不了解会误以为锁或 CAS 问题。  
怎么用：LongAdder/Striped，分片数组，@Contended（JDK 内部注解）或手动填充冗余字段隔离热点；减少多写同一对象字段。  
关键细节：过度填充浪费内存；仅在分析确认热点后使用；避免自动拆箱频繁创建。  
面试提示：描述“AtomicLong 在高并发下退化”→引出伪共享→说明解决手段。

## 16. 文件描述符 (FD) 管理与限制 [4]
是什么：FD 表示打开文件、套接字、管道等资源；系统和进程有最大数量限制（ulimit -n）。  
为什么：FD 耗尽导致新连接失败或无法打开文件；常见于高并发/未正确关闭流。  
怎么用：监控 lsof | wc；启用连接池和长连接复用；定期清理闲置连接；调高限制与内核相关参数（fs.file-max）。  
关键细节：TIME_WAIT 多占用端口但不是 FD 泄漏；CLOSE_WAIT 表示未关闭；监控句柄趋势预警泄漏。  
面试提示：给出“FD 耗尽排查清单：lsof→分类型→定位未关闭代码路径”。

## 17. 性能指标与排障方法论 [5]
是什么：结构化故障定位流程：现象→范围→指标→假设→验证→根因→修复→预防；指标包括 CPU、Load、iowait、GC、线程、网络重传、磁盘队列等。  
为什么：避免盲试；提高协作与复盘质量；减少恢复时间 (MTTR)。  
怎么用：按层收集指标；建立基线对比异常幅度；单一假设验证后进入下一步；记录证据形成知识库。  
关键细节：Load 包括可运行与不可中断 I/O 进程；iowait 高指 I/O 阻塞；GC 停顿与堆增长趋势结合判断泄漏 vs 正常增长；线程 Dump 频次控制。  
面试提示：完整讲述一次“尾延迟飙升”排查路径（指标→假设→抓包→修复）。

## 18. TCP 状态与 TIME_WAIT / CLOSE_WAIT 分析 [4]
是什么：TCP 状态机反映连接生命周期；TIME_WAIT 是主动关闭方等待残留报文过期；CLOSE_WAIT 是被动关闭方未调用 close 释放资源。  
为什么：大量 TIME_WAIT 消耗端口与内核表；CLOSE_WAIT 堆积代表资源泄漏或协议处理不完整。  
怎么用：ss -s 或 ss -ant | grep 状态；启用连接池/KeepAlive 减少短连接；排查代码未关闭输入流或未消费完数据导致 CLOSE_WAIT。  
关键细节：TIME_WAIT 等待 2MSL；SO_REUSEADDR/PORT 缓解端口占用需谨慎；半开连接清理机制。  
面试提示：描述“大量 CLOSE_WAIT 原因→未关闭输入流→修复”真实案例。

## 19. 常见线上故障模式 [5]
是什么：CPU 单核拉满（热点锁/循环）、频繁 Full GC、IO wait 高、FD 耗尽、线程死锁、网络重传激增、磁盘队列过长。  
为什么：提前认知模式可缩短定位时间；建立 Runbook 快速执行恢复步骤。  
怎么用：监控触发自动收集线程 Dump、GC 日志、perf 报告；按模式匹配工具链；自动化隔离故障组件。  
关键细节：死锁用 jstack 检查 BLOCKED 循环；单核拉满但总体 CPU 未满→热点单线程瓶颈；重传激增→网络抖动或发送端大量拥塞。  
面试提示：快速从症状描述给出“工具+步骤”组合体现经验。

## 20. 时钟与时间同步 (NTP / 单调时钟) [3]
是什么：系统时间通过 NTP/Chrony 同步；单调时钟（monotonic）不受系统时间调整，适合度量间隔。  
为什么：时间回拨影响分布式 ID、缓存过期、日志顺序；度量性能若用 wall clock 会受跳变干扰。  
怎么用：用 System.nanoTime 统计耗时；监控时钟偏移；为时间敏感算法（Snowflake）加回拨保护。  
关键细节：System.currentTimeMillis 受调整；NTP 可能大步修正或渐进；漂移过大需告警。  
面试提示：说明“为什么不能用 currentTimeMillis 度量方法执行时间”。

## 21. 容器内 JVM 参数与行为 [3]
是什么：JVM 在容器环境读取 cgroup 限制动态决定堆大小、并行 GC 线程数等；低版本 JDK 不识别 cgroup。  
为什么：默认推导可能不适配实际工作负载（堆过小/GC 频繁）；需要人工校准。  
怎么用：显式设置 -Xms/-Xmx 保持稳定；调 MaxRAMPercentage；限制直接内存（-XX:MaxDirectMemorySize）；观察 GC 与内存曲线。  
关键细节：容器内 free 命令不代表可用给 JVM；限制过低导致频繁 Full GC；CPU quota 影响并行阶段效率。  
面试提示：描述“容器迁移后 Full GC 激增”排查思路（查看 cgroup 限制→调整堆）。

## 22. 安全机制 (SELinux / AppArmor) [2]
是什么：强制访问控制 (MAC) 框架，基于策略限制进程访问文件、端口、系统调用；AppArmor 以路径为基础，SELinux 基于上下文。  
为什么：部署环境默认启用会导致应用访问文件或端口失败，若未了解可能误判为权限或程序 bug。  
怎么用：审计日志 (/var/log/audit.log) 查看拒绝；暂时切 permissive 模式验证；添加策略放行所需操作。  
关键细节：最小权限原则；策略更新需重载；容器与宿主机交互影响。  
面试提示：说明快速判定是 SELinux 阻断的路径：触发→查看 audit→确认 context。

## 23. eBPF 可观测性基础 [2]
是什么：eBPF 在内核安全虚拟机中加载字节码探针，低开销动态采集事件（网络、系统调用、调度）。  
为什么：比传统内核模块更安全；更细粒度追踪热点延迟与异常。  
怎么用：使用 bpftrace 或 bcc 工具编写脚本抓取函数、系统调用、延迟分布；结合可视化。  
关键细节：有指令数量与循环限制；需要较新内核；错误脚本可能被内核拒绝验证。  
面试提示：对比 perf（采样）与 eBPF（事件与过滤灵活）优劣。

## 24. io_uring 新式异步 I/O [2]
是什么：Linux 新接口，用提交队列/完成队列减少系统调用数量与上下文切换，实现更高效异步文件与网络操作。  
为什么：在高并发 I/O 场景减少内核与用户态来回；提升吞吐与降低延迟。  
怎么用：目前 Java 生态仍以 epoll/NIO 为主；了解概念便于未来框架跟进；原生应用可利用 liburing。  
关键细节：需较新内核版本；部分操作仍回退传统路径；正确处理批量提交与完成事件。  
面试提示：概述“区别在于批量与减少 syscall 往返”。

## 25. 资源降级与背压策略 [4]
是什么：当系统即将过载时主动限制入口（限流）、排队、快速失败或返回降级结果，保护核心功能与总体稳定。  
为什么：无背压系统会在峰值瞬间爆炸（线程池堆积、队列耗尽、全链路放大重试导致雪崩）。  
怎么用：令牌桶控制瞬时 QPS；漏桶平滑；线程池拒绝策略定制（抛异常/快速返回）；区分核心与非核心路径采用不同策略；监控队列等待时间与拒绝率。  
关键细节：重试风暴放大问题；降级返回需标识来源；链路最薄弱下游决定整体速度；异步排队监控尾延迟。  
面试提示：讲述“高峰期接口未崩溃因为限流+快速失败”场景。

## 26. Java 与硬件协同优化 [5]
是什么：利用硬件特性（缓存、分支预测、NUMA、向量化）与 JVM 优化（逃逸分析、内联、对象布局）协同提升吞吐与降低延迟。  
为什么：纯算法优化不够；深入硬件层面可以获取额外倍数级性能提升，减少 GC 压力与锁争用。  
怎么用：批量处理减少方法调用与分支；结构化为数组/紧凑对象；减少临时对象（减少 GC）；使用并发友好结构 (LongAdder, ConcurrentHashMap)；性能基准（JMH）验证改动。  
关键细节：对象头与指针压缩（UseCompressedOops）；TLAB 快速分配；逃逸分析消除锁；分支倾斜利用预测；伪共享与 false sharing 避免。  
面试提示：举“链表→数组遍历减少随机访问 + 分支预测更稳定”案例。

## 27. 分析与排障结构化步骤 [5]
是什么：故障处理闭环：描述现象→确定影响范围→收集关键指标→建立候选假设→逐一验证→确认根因→实施修复→制定预防措施。  
为什么：降低 MTTR 与避免重复踩坑；提升团队协作与知识沉淀。  
怎么用：初步分类（性能/功能/资源）；建立时间线；每次验证只改一项；最终撰写复盘记录方案与监控补强。  
关键细节：避免一次性修改多参数；区分相关性与因果；保留现场数据（日志/指标）用于验证。  
面试提示：复述一个真实案例强调“证据链 + 单一假设验证”。

## 28. 线程阻塞 / 调度延迟诊断 [4]
是什么：线程长时间 WAITING/BLOCKED 或任务排队时长上升导致响应延迟；可能源于锁争用、IO 阻塞或外部依赖慢。  
为什么：不及时诊断会演变为雪崩（更多线程加入等待）；尾延迟拉高。  
怎么用：周期性 jstack；分析同一锁持有者栈；监控线程池 active/queue；使用 async-profiler 看阻塞时间；必要时锁分段或改用无锁结构。  
关键细节：死锁与长等待区分；AQS 队列长度；虚拟线程减少阻塞线程成本但不解决根本慢资源。  
面试提示：列出“jstack + arthas thread + perf”初步工具组合。

## 29. 性能优化优先级 (80/20) [4]
是什么：优化顺序：算法复杂度→数据结构→I/O 模式→内存分配/GC→锁与并发控制→缓存/分支微调。  
为什么：过早关注微观（如单条指令）忽略宏观瓶颈浪费时间；80% 效果往往来自前几层。  
怎么用：先用基准/剖析确定热点；消除 O(n^2)/过度嵌套；换结构（链表→数组/跳表→哈希）；减少分配与复制；再考虑分支/向量化。  
关键细节：对象池不适合短生命周期轻量对象；微优化牺牲可读性需谨慎；指标驱动而非猜测。  
面试提示：举从 O(n^2) 改为 O(n log n) 带来数量级提升的案例。

## 30. 常见误区与防范 [3]
是什么：常见错误观点：线程越多越快；所有字段加 volatile 更安全；关闭 swap 一定提高性能；对象池总能减少 GC。  
为什么：误区导致资源浪费甚至性能下降（过多线程上下文切换、volatile 增一致性流量、无 swap OOM 崩溃）。  
怎么用：基准测试证明策略；理解硬件 + JVM 行为；最小必要同步；合理使用缓存与池。  
关键细节：volatile 不提供复合原子；swap 适度有兜底作用；对象池化增加复杂度与内存占用；GC 对短命对象非常高效。  
面试提示：分享一个曾坚持的误区（如“线程加到 2×CPU 更快”）及纠正过程。

---

### 快速场景映射示例
| 场景 | 指标现象 | 可能根因 | 首选工具 |
| ---- | -------- | -------- | -------- |
| CPU 单核 100% | 某核 usr 高，其余低 | 热点锁/单线程瓶颈/分支失败 | perf / async-profiler |
| 大量 TIME_WAIT | 端口近耗尽 | 短连接风暴/缺乏复用 | ss / netstat |
| iowait 高 | %iowait 高、磁盘队列长 | 随机写/存储瓶颈 | iostat / pidstat |
| Full GC 频繁 | GC 日志停顿多 | 堆过小/泄漏/碎片化 | jstat / GC log / MAT |
| FD 耗尽 | 打开句柄逼近上限 | 连接泄漏/文件未关闭 | lsof / ulimit |
| 延迟抖动 | P99 激增 | GC 停顿 / 线程阻塞 / 重传 | jfr / jstack / tcpdump |
| Runnable 激增 | runnable 数飙升 | 锁争用 / IO 阻塞误判 | jstack / perf locks |

### 面试回答框架建议
1. 主线：硬件底座（缓存→一致性）→运行时（线程/调度）→内存（分页/GC）→IO（零拷贝/多路复用）→系统资源与排障。  
2. 性能：先算法与数据结构，再内存与并发，再网络与 IO，最后微优化。  
3. 案例：结构化描述（现象→指标→假设→验证→根因→修复→预防）体现资深思维。

(完)